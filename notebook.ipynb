{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import important libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns \n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from numpy.linalg import LinAlgError \n",
    "from functools import reduce \n",
    "\n",
    "from sklearn.neighbors import KernelDensity, KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:488: SyntaxWarning: invalid escape sequence '\\h'\n",
      "<>:488: SyntaxWarning: invalid escape sequence '\\h'\n",
      "C:\\Users\\oyetu\\AppData\\Local\\Temp\\ipykernel_33192\\1872246863.py:488: SyntaxWarning: invalid escape sequence '\\h'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# create Simulated Experiment\n",
    "\n",
    "class Simulated_Experiment:\n",
    "    def __init__(self, T, N, L, nan_rate=0.4):\n",
    "        \"\"\" \n",
    "        T: Number of days\n",
    "        N: Number of stocks/companies\n",
    "        L: Number of characteristics\n",
    "        nan_rate: Rate that controls the masking rate for the simulated data\n",
    "        \n",
    "        \"\"\"\n",
    "        self.T = T \n",
    "        self.N = N \n",
    "        self.L = L  \n",
    "\n",
    "        self.nan_rate = nan_rate \n",
    "\n",
    "\n",
    "    def generate_masked_data(self):\n",
    "        T, N, L = self.T, self.N, self.L \n",
    "        panel = np.zeros((T,N,L))\n",
    "        for t in range(T):\n",
    "            np.random.seed(t) # for reproducibility \n",
    "            # Generate random mean vector (mu)\n",
    "            mu = np.random.normal(size=L)\n",
    "            # Generate random covariance matrix (Sigma)\n",
    "            Sigma = np.random.rand(L,L)\n",
    "            Sigma = Sigma @ Sigma.T # Ensure positive-definite matrix \n",
    "            panel[t,::] = np.random.multivariate_normal(mu, Sigma, N)\n",
    "\n",
    "        raw_chars = panel \n",
    "\n",
    "        self.raw_chars = raw_chars # raw characteristics\n",
    "\n",
    "        # convert the raw_chars into rank_chars \n",
    "        rank_chars = percentile_rank_panel(raw_chars)\n",
    "        self.rank_chars = rank_chars \n",
    "\n",
    "\n",
    "        # Simulate missing data \n",
    "        masked_rank_chars = np.array([simulate_nan(rank_chars[t], nan_rate=self.nan_rate)['X'] for t in range(T)])\n",
    "\n",
    "        self.masked_rank_chars = masked_rank_chars\n",
    "\n",
    "        return masked_rank_chars\n",
    "    \n",
    "    def evaluate_imputation_performance(self, method='xs', params=\"\"):\n",
    "        \"\"\" \n",
    "        Function can call any available imputation method \n",
    "        method could be 'em', 'xs', 'b_xs', 'xs-median', 'forward_filling'\n",
    "        \"\"\"\n",
    "\n",
    "        # create an object of Imputer and just use of the defaults\n",
    "        # then measure performance of imputation\n",
    "\n",
    "        impute_model = Imputer(self.masked_rank_chars)\n",
    "\n",
    "        # put params as input of each function\n",
    "        if method == 'em':\n",
    "            rank_imputed_chars = impute_model.impute_with_em(params)\n",
    "        \n",
    "        elif method == 'xs':\n",
    "            rank_imputed_chars = impute_model.impute_with_xs(params)\n",
    "\n",
    "        else: # Default \n",
    "            print(\"Method not recognied\")\n",
    "            print(\"Using default cross-sectional model\")\n",
    "\n",
    "            rank_imputed_chars = impute_model.impute_with_xs()\n",
    "        \n",
    "        self.rank_imputed_chars = impute_model.rank_imputed_chars \n",
    "        self.missing_mask_overall = impute_model.missing_mask_overall\n",
    "\n",
    "        # calculate metrics for the imputation model\n",
    "        # evaluate performance\n",
    "        metrics = self.evaluate_imputations(self.rank_chars)\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def evaluate_imputations(self, rank_chars):\n",
    "        \"\"\" \n",
    "        Adapted function to measure the quality of the imputation\n",
    "        rank_chars : the complete ranked characteristics\n",
    "        \"\"\"\n",
    "        truth_panel = rank_chars\n",
    "\n",
    "        tgt = np.copy(truth_panel)\n",
    "        T, N, L = tgt.shape\n",
    "        imputed = np.zeros((T,N,L)) # initialized the panel\n",
    "        imputed[~self.missing_mask_overall] = np.nan # everywhere should be nan\n",
    "        imputed[self.missing_mask_overall] = self.rank_imputed_chars[self.missing_mask_overall]\n",
    "\n",
    "        tgt[np.isnan(imputed)] = np.nan # anyone that is still empty in the imputed chars, make them empty in the target\n",
    "\n",
    "        # compute rmse and r2\n",
    "        rmse = compute_rmse(tgt, imputed)\n",
    "        r2 = compute_r2(tgt, imputed)\n",
    "\n",
    "        metrics = {'rmse': rmse,\n",
    "                   'r2': r2}\n",
    "        \n",
    "        print(metrics)\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "class Imputer:\n",
    "    def __init__(self, masked_rank_chars):\n",
    "        \"\"\" \n",
    "        masked_rank_chars : panel data with missing points\n",
    "        \"\"\"\n",
    "        self.masked_rank_chars = masked_rank_chars\n",
    "\n",
    "        T, N, L = masked_rank_chars.shape \n",
    "\n",
    "        self.T, self. N, self.L = T, N, L \n",
    "\n",
    "        # set defaults for the different methods\n",
    "\n",
    "        # em\n",
    "        self.em_params = {\n",
    "            'max_iter': 20,\n",
    "            'eps': 1e-03,\n",
    "            'min_xs_obs': 1\n",
    "        }\n",
    "\n",
    "        # xs-median\n",
    "        self.xs_median_params = {\n",
    "            'min_xs_obs': 1\n",
    "        }\n",
    "\n",
    "        # xs\n",
    "        self.xs_params = {\n",
    "            'K': L,\n",
    "            'time_varying_loadings': True,\n",
    "            'reg_param': 0.01/L,\n",
    "            'eval_weight_lmbda': True,\n",
    "            'shrink_lmbda': False,\n",
    "            'min_xs_obs': 1\n",
    "        }\n",
    "\n",
    "        # b-xs\n",
    "        self.b_xs_params = {\n",
    "            'K': L,\n",
    "            'time_varying_loadings': True,\n",
    "            'reg_param': 0.01/L,\n",
    "            'eval_weight_lmbda': True,\n",
    "            'shrink_lmbda': False,\n",
    "            'min_xs_obs': 1\n",
    "        }\n",
    "\n",
    "    def impute_with_em(self, params=\"\"):\n",
    "\n",
    "        # check if params is empty\n",
    "\n",
    "        if params == \"\":\n",
    "            params = self.em_params \n",
    "        \n",
    "        else:\n",
    "            params = params \n",
    "\n",
    "        max_iter = params['max_iter']\n",
    "        eps = params['eps']\n",
    "        min_xs_obs = params['min_xs_obs']\n",
    "\n",
    "        T,N,L = self.masked_rank_chars.shape \n",
    "        min_chars = min_xs_obs # minimum number of characteristics that must be observed\n",
    "        char_panel = np.copy(self.masked_rank_chars)\n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "        self.missing_mask_overall = missing_mask_overall \n",
    "        return_mask = np.sum(~missing_mask_overall, axis=2) >= min_chars \n",
    "\n",
    "        char_panel[np.sum(~np.isnan(missing_mask_overall), axis=2) < min_chars] = np.nan \n",
    "\n",
    "        em_imputations = np.zeros((T,N,L)) # T X N X L \n",
    "        em_imputations[:,:] = np.nan \n",
    "\n",
    "        imputations = [impute_em(char_panel[t]) for t in range(T)]\n",
    "\n",
    "        for t in range(T):\n",
    "            em_imputations[t, return_mask[t]] = imputations[t]['X_imputed'][return_mask[t]] # copying imputations into em_imputations\n",
    "\n",
    "        self.rank_imputed_chars = em_imputations \n",
    "\n",
    "        return self.rank_imputed_chars \n",
    "    \n",
    "    def impute_with_xs_median(self, params=\"\"):\n",
    "        # check if params is empty\n",
    "\n",
    "        if params == \"\":\n",
    "            params = self.xs_median_params \n",
    "\n",
    "        else:\n",
    "            params = params \n",
    "\n",
    "        min_chars = params['min_xs_obs']\n",
    "\n",
    "        # run the baseline code\n",
    "        char_panel = np.copy(self.masked_rank_chars)\n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "\n",
    "        char_panel[np.sum(~np.isnan(missing_mask_overall), axis=2) < min_chars] = np.nan \n",
    "\n",
    "        # get the missing mask after min_chars is enforced \n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "        self.missing_mask_overall = missing_mask_overall \n",
    "\n",
    "        return_mask = np.sum(~missing_mask_overall, axis=2) >= min_chars \n",
    "\n",
    "        imputed_chars = np.copy(char_panel) # this is the rank data \n",
    "\n",
    "        new_imputation = xs_median_impute(imputed_chars)\n",
    "\n",
    "        # revisit this --- perhaps using the return_mask is best\n",
    "        imputed_chars[missing_mask_overall] = new_imputation[missing_mask_overall]\n",
    "\n",
    "        self.rank_imputed_chars = imputed_chars\n",
    "\n",
    "        return self.rank_imputed_chars \n",
    "    \n",
    "    def impute_with_forward_filling(self, params=\"\"):\n",
    "        \"\"\" \n",
    "        Make Imputations using forward filling\n",
    "        \"\"\"\n",
    "\n",
    "        # run the baseline code\n",
    "        char_panel = np.copy(self.masked_rank_chars)\n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "\n",
    "        self.missing_mask_overall = missing_mask_overall\n",
    "\n",
    "        imputed_chars = np.copy(char_panel) # rank data\n",
    "        \n",
    "        new_imputation = simple_impute(imputed_chars)\n",
    "\n",
    "        # revisit this --- perhaps using the return_mask is best\n",
    "        imputed_chars[missing_mask_overall] = new_imputation[missing_mask_overall]\n",
    "\n",
    "        self.rank_imputed_chars = imputed_chars\n",
    "\n",
    "        return self.rank_imputed_chars \n",
    "\n",
    "\n",
    "    def impute_with_xs(self, params=\"\"):\n",
    "        \"\"\" \n",
    "        Make Imputations with cross-sectional approach\n",
    "        \"\"\"\n",
    "\n",
    "        if params == \"\": # check if params is empty\n",
    "            params = self.xs_params\n",
    "        else:\n",
    "            params = params \n",
    "\n",
    "        self.min_xs_obs = params['min_xs_obs']\n",
    "        self.K = params['K']\n",
    "        self.time_varying_loadings = params['time_varying_loadings']\n",
    "        self.reg_param = params['reg_param']\n",
    "        self.eval_weight_lmbda = params['eval_weight_lmbda']\n",
    "        self.shrink_lmbda = params['shrink_lmbda']\n",
    "\n",
    "\n",
    "        # run the baseline code\n",
    "        char_panel = np.copy(self.masked_rank_chars)\n",
    "        min_chars = self.min_xs_obs\n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "\n",
    "        char_panel[np.sum(~np.isnan(missing_mask_overall), axis=2) < min_chars] = np.nan \n",
    "\n",
    "        # obtain modified missing mask after enforcing min_chars\n",
    "        \n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "        self.missing_mask_overall = missing_mask_overall \n",
    "        return_mask = np.sum(~missing_mask_overall, axis=2) >= min_chars\n",
    "\n",
    "        imputed_chars = np.copy(char_panel) # rank data\n",
    "        \n",
    "        mu = np.nanmean(imputed_chars, axis=1) # important for the algorithm stability\n",
    "\n",
    "        lmbda, cov_mat = estimate_lambda(imputed_chars, self.T, self.K,self.min_xs_obs, \n",
    "                                        self.time_varying_loadings,\n",
    "                                        reg=self.reg_param, eval_weight_lmbda = self.eval_weight_lmbda,\n",
    "                                        shrink_lmbda=self.shrink_lmbda)\n",
    "\n",
    "        assert np.sum(np.isnan(lmbda)) == 0, f\"lambda should contain no nans, {np.argwhere(np.isnan(lmbda))}\"\n",
    "\n",
    "        gamma_ts = np.zeros((char_panel.shape[0], char_panel.shape[1], self.K))  # T X N X K \n",
    "        gamma_ts[:,:] = np.nan \n",
    "\n",
    "        def get_gamma_t(ct, present, to_impute, lmbda, time_varying_lambdas, t):\n",
    "\n",
    "            if time_varying_lambdas:\n",
    "                gamma_t = lmbda[t].T.dot(ct.T).T # gamma_t = ct @ lmbda[t]\n",
    "                gamma_t = get_optimal_A(lmbda[t].T, gamma_t, present, ct, L=self.L, \n",
    "                                        idxs=to_impute, reg=self.reg_param, mu=mu[t])\n",
    "            else:\n",
    "                gamma_t = lmbda[t].T.dot(ct.T).T # gamma_t = ct @ lmbda[t]\n",
    "                gamma_t = get_optimal_A(lmbda.T, gamma_t, present, ct, L=self.L, \n",
    "                                        idxs=to_impute, reg=self.reg_param, mu=mu[t])\n",
    "            \n",
    "            return gamma_t \n",
    "        \n",
    "        gammas = [get_gamma_t(\n",
    "            ct=char_panel[t],\n",
    "            present= ~np.isnan(char_panel[t]),\n",
    "            to_impute= np.argwhere(return_mask[t]).squeeze(),\n",
    "            lmbda=lmbda,\n",
    "            time_varying_lambdas=self.time_varying_loadings, t=t,\n",
    "        ) for t in range(self.T)]\n",
    "\n",
    "        for t in range(self.T):\n",
    "            gamma_ts[t, return_mask[t]] = gammas[t][return_mask[t]] # copying gamma into gamma_ts \n",
    "\n",
    "        self.rank_imputed_chars = imputed_chars\n",
    "\n",
    "        return self.rank_imputed_chars \n",
    "    \n",
    "\n",
    "    def impute_with_b_xs(self, params=\"\"):\n",
    "        \"\"\" \n",
    "        Cross-sectional imputation + backward time series information\n",
    "        \"\"\"\n",
    "\n",
    "        if params == \"\": # check if params is empty\n",
    "            params = self.b_xs_params\n",
    "        else:\n",
    "            params = params \n",
    "\n",
    "        self.min_xs_obs = params['min_xs_obs']\n",
    "        self.K = params['K']\n",
    "        self.time_varying_loadings = params['time_varying_loadings']\n",
    "        self.reg_param = params['reg_param']\n",
    "        self.eval_weight_lmbda = params['eval_weight_lmbda']\n",
    "        self.shrink_lmbda = params['shrink_lmbda']\n",
    "\n",
    "        # run the xs function\n",
    "        xs_imputation = self.impute_with_xs(params)\n",
    "\n",
    "        # run the baseline code\n",
    "        char_panel = np.copy(self.masked_rank_chars)\n",
    "        min_chars = self.min_xs_obs\n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "\n",
    "        char_panel[np.sum(~np.isnan(missing_mask_overall), axis=2) < min_chars] = np.nan \n",
    "\n",
    "        # obtain modified missing mask after enforcing min_chars\n",
    "        \n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "        self.missing_mask_overall = missing_mask_overall \n",
    "        return_mask = np.sum(~missing_mask_overall, axis=2) >= min_chars\n",
    "\n",
    "        imputed_chars = np.copy(char_panel) # rank data\n",
    "        \n",
    "        mu = np.nanmean(imputed_chars, axis=1) # important for the algorithm stability\n",
    "\n",
    "        # compute the residuals\n",
    "        residuals = simple_impute(imputed_chars) - xs_imputation\n",
    "\n",
    "        local_bw = impute_chars(char_panel, xs_imputation, residuals, suff_stat_method='last_val', constant_beta=False)\n",
    "\n",
    "        imputed_chars[missing_mask_overall] = local_bw[missing_mask_overall]\n",
    "\n",
    "        local_bw_missing_mask = np.isnan(imputed_chars) # obtain the missing mask in the already filled data\n",
    "\n",
    "        # improving data quality by imputing from the xs_imputation\n",
    "        imputed_chars[local_bw_missing_mask] = xs_imputation[local_bw_missing_mask]\n",
    "\n",
    "        self.rank_imputed_chars = imputed_chars\n",
    "\n",
    "        return self.rank_imputed_chars \n",
    "    \n",
    "    def evaluate_imputations(self, rank_chars):\n",
    "        \"\"\" \n",
    "        Adapted function to measure the quality of the imputation\n",
    "        rank_chars : the complete ranked characteristics\n",
    "        \"\"\"\n",
    "        truth_panel = rank_chars\n",
    "\n",
    "        tgt = np.copy(truth_panel)\n",
    "        T, N, L = tgt.shape\n",
    "        imputed = np.zeros((T,N,L)) # initialized the panel\n",
    "        imputed[~self.missing_mask_overall] = np.nan # everywhere should be nan\n",
    "        imputed[self.missing_mask_overall] = self.rank_imputed_chars[self.missing_mask_overall]\n",
    "\n",
    "        tgt[np.isnan(imputed)] = np.nan # anyone that is still empty in the imputed chars, make them empty in the target\n",
    "\n",
    "        # compute rmse and r2\n",
    "        rmse = compute_rmse(tgt, imputed)\n",
    "        r2 = compute_r2(tgt, imputed)\n",
    "\n",
    "        metrics = {'rmse': rmse,\n",
    "                   'r2': r2}\n",
    "        \n",
    "        print(metrics)\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "\n",
    "# helper functions\n",
    "def percentile_rank(x, UNK=np.nan):\n",
    "    \"\"\" \n",
    "    utility method to quantile rank a vector\n",
    "    \"\"\"\n",
    "\n",
    "    mask = np.logical_not(np.isnan(x))\n",
    "    x_copy = np.copy(x)\n",
    "    x_mask = x_copy[mask]\n",
    "    n = len(x_mask)\n",
    "\n",
    "    if n > 1:\n",
    "        temp = [(i, x_mask[i]) for i in range(n)]\n",
    "        temp_sorted = sorted(temp, key=lambda t: t[1])\n",
    "        idx = sorted([(temp_sorted[i][0], i) for i in range(n)], key=lambda t: t[0])\n",
    "        x_copy[mask] = np.array([idx[i][1] for i in range(n)]) / (n-1)\n",
    "\n",
    "    elif n == 1:\n",
    "        x_copy[mask] = 0.5\n",
    "    return x_copy \n",
    "\n",
    "def percentile_rank_panel(char_panel): # very useful function\n",
    "    \"\"\" \n",
    "    utility method to quantile rank the characteristics or features\n",
    "    \"\"\"\n",
    "    ret_panel = np.zeros(char_panel.shape)\n",
    "    ret_panel[:,:,:] = np.nan\n",
    "    for t in range(char_panel.shape[0]):\n",
    "        for i in range(char_panel.shape[2]):\n",
    "            ret_panel[t,:,i] = percentile_rank(char_panel[t,:,i])\n",
    "\n",
    "\n",
    "    return ret_panel\n",
    "\n",
    "\n",
    "def get_cov_mat(char_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the covariance matrix of a partially observed panel using the method from Xiong & Pelger\n",
    "    Parameters\n",
    "    ----------\n",
    "        char_matrix : the panel over which to calculate the covariance N x L\n",
    "    \"\"\"\n",
    "    ct_int = (~np.isnan(char_matrix)).astype(float)\n",
    "    ct = np.nan_to_num(char_matrix)\n",
    "    mu = np.nanmean(char_matrix, axis=0).reshape(-1, 1)\n",
    "    temp = ct.T.dot(ct) \n",
    "    temp_counts = ct_int.T.dot(ct_int)\n",
    "    sigma_t = temp / temp_counts - mu @ mu.T\n",
    "    return mu,sigma_t\n",
    "\n",
    "\n",
    "def get_data_panel(data, N_column_name, start_date=None):\n",
    "    \"\"\" \n",
    "    N_column_name could be the company column\n",
    "    fetch data from user input\n",
    "    \"\"\"\n",
    "\n",
    "    if start_date is not None:\n",
    "        data = data.loc[data.date >= start_date]\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "    dates = data['date'].unique() \n",
    "    dates.sort() # sort the dates\n",
    "    Ns = data[N_column_name].unique() # obtain the unique Ns\n",
    "\n",
    "    date_vals = [date for date in dates]\n",
    "    chars = np.array([char for char in data.columns.tolist() if char not in ['date', N_column_name]])\n",
    "    chars.sort()\n",
    "\n",
    "    rank_chars = np.zeros((len(date_vals), Ns.shape[0], len(chars))) # create the panel\n",
    "    rank_chars[:,:,:] = np.nan \n",
    "\n",
    "\n",
    "    N_map = {}\n",
    "    for i, N_ in enumerate(Ns):\n",
    "        N_map[N_] = i \n",
    "\n",
    "    for i, date in enumerate(dates):\n",
    "        date_data = data.loc[data['date'] == date].sort_values(by=N_column_name)\n",
    "        date_Ns = date_data[N_column_name].tolist()\n",
    "        N_inds_for_date = [N_map[N_] for N_ in date_Ns]\n",
    "        rank_chars[i, N_inds_for_date,:] = date_data[chars].to_numpy()\n",
    "\n",
    "    return rank_chars, chars, date_vals, Ns\n",
    "\n",
    "\n",
    "def estimate_lambda(char_panel, num_days_train, K, min_chars,\n",
    "                    time_varying_loadings=False, eval_weight_lmbda=True,\n",
    "                    shrink_lmbda=False, reg=0, window_size=1):\n",
    "    \n",
    "    \"\"\" \n",
    "    Fit the cross-sectional Loadings using XP method\n",
    "    Parameters\n",
    "    ----------\n",
    "        char_panel: the panel over which to fit the model T X N X L\n",
    "        num_days_train: if fitting a global model, the number of days over which to fit the loadings\n",
    "        K: the number of cross-sectional factors\n",
    "        min_chars: the minimum number of observations required for an entity to be included in the sample\n",
    "        time_varying_loadings = False: whether or not to allow the loadings to vary over time\n",
    "\n",
    "    Formula\n",
    "    --------\n",
    "    \\hat{\\Lambda^t} = \\hat{V^t} (\\hat{D^t}^{1/2})\n",
    "\n",
    "    \"\"\"\n",
    "    # create a mask to show when the minimum number of characteristics is observed\n",
    "    min_char_mask = np.expand_dims(np.sum(~np.isnan(char_panel), axis=2) >= min_chars, axis=2)\n",
    "\n",
    "    cov_mats = []\n",
    "\n",
    "    for t in range(num_days_train):\n",
    "        cov_mats.append(get_cov_mat(char_panel[t][1])) # Send the N X L to get the characteristic covariance matrix of dim L X L\n",
    "\n",
    "    cov_mats_sum = sum(cov_mats) * (1/len(cov_mats)) # Takes the average of the covariance matrix\n",
    "\n",
    "    if time_varying_loadings: # local-based models have time-varying lambdas\n",
    "        lmbda = []\n",
    "        cov_mat = []\n",
    "        printed = False \n",
    "\n",
    "        for t in range(len(cov_mats)): # in this case, we want to avoid look-ahead bias, so we keep cov_mat as it was at day t\n",
    "            cov_mats_sum = sum(cov_mats[max(0, t-window_size+1): t+1]) * (1/window_size)\n",
    "\n",
    "            eig_vals, eig_vects = np.linalg.eigh(cov_mats_sum) # obtain the eigenvalues and eigenvectors, from the covariance matrix\n",
    "            idx = np.abs(eig_vals).argsort()[::-1]\n",
    "            if eval_weight_lmbda:\n",
    "                if shrink_lmbda:\n",
    "                    lmbda.append(eig_vects[:, idx[:K]] *\n",
    "                                np.maximum(np.sqrt(np.sqrt(np.maximum(eig_vals[idx[:K]].reshape(1,-1),0))) - reg, 0))\n",
    "                else:\n",
    "                    lmbda.append(eig_vects[:, idx[:K]] * np.sqrt(np.maximum(eig_vals[idx[:K]].reshape(1,-1), 0)))\n",
    "            else:\n",
    "                lmbda.append(eig_vects[:, idx[:K]])\n",
    "            assert np.all(~np.isnan(lmbda[-1])), lmbda\n",
    "            cov_mat.append(cov_mats_sum)\n",
    "\n",
    "\n",
    "    else:\n",
    "        tgt_mat = cov_mats_sum\n",
    "        eigh_vals, eig_vects = np.linalg.eigh(tgt_mat)\n",
    "\n",
    "        idx = np.abs(eig_vals).argsort()[::-1]\n",
    "        if eval_weight_lmbda:\n",
    "            if shrink_lmbda:\n",
    "                lmbda = eig_vects[:, idx[:K]] * np.maximum(np.sqrt(np.sqrt(eig_vals[idx[:K]].reshape(1,-1))) - reg, 0)\n",
    "            else:\n",
    "                lmbda = eig_vects[:, idx[:K]] * np.sqrt(np.maximum(0, eig_vals[idx[:K]].reshape(1, -1)))\n",
    "        else:\n",
    "            lmbda = eig_vects[:, idx[:K]]\n",
    "        cov_mat = tgt_mat\n",
    "    return lmbda, cov_mat \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_optimal_A(B, A, present, cl, L, idxs=[], reg=0, mu=None):\n",
    "    \"\"\"\n",
    "    Get optimal A for cl = AB given that X is (potentially) missing data\n",
    "    Parameters\n",
    "    ----------\n",
    "        B : matrix B\n",
    "        A : matrix A, will be overwritten\n",
    "        present: boolean mask of present data\n",
    "        cl: matrix cl\n",
    "        idxs: indexes which to impute\n",
    "        reg: optinal regularization penalty\n",
    "        mu: mean of the partially-observed characteristics\n",
    "    \"\"\"\n",
    "    A[:,:] = np.nan\n",
    "    for i in idxs:\n",
    "        present_i = present[i,:]\n",
    "        Xi = cl[i,:]\n",
    "        Xi = Xi[present_i]\n",
    "        Bi = B[:,present_i]\n",
    "        assert np.all(~np.isnan(Bi)) and np.all(~np.isinf(Bi))\n",
    "        effective_reg = reg \n",
    "        lmbda = effective_reg * np.eye(Bi.shape[1])\n",
    "\n",
    "        if mu is not None:\n",
    "            Xi = Xi - mu.T[present_i]\n",
    "        try:\n",
    "            A[i,:] = Bi @ np.linalg.lstsq(Bi.T @ Bi / L + lmbda, Xi / L, rcond=0)[0]\n",
    "        except LinAlgError as e:\n",
    "            lmbda = np.eye(Bi.shape[1])\n",
    "            A[i,:] = Bi @ np.linalg.lstsq(Bi.T @ Bi / L + lmbda, Xi / L, rcond=0)[0]\n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "def get_sufficient_statistics_last_val(characteristics_panel, max_delta=None,\n",
    "                                      residuals=None):\n",
    "    \"\"\"\n",
    "    Get the last observed value for a panel time series \n",
    "    Parameters\n",
    "    ----------\n",
    "        characteristics_panel : the time series panel, T x N x L\n",
    "        max_delta=None : Optional, the maximum lag which is allowed for a previously observed value\n",
    "        residuals=None : Optional, residuals T x N x L, the residuals the factor model applied to the time\n",
    "                        series panel\n",
    "    \"\"\"\n",
    "    T, N, L = characteristics_panel.shape\n",
    "    last_val = np.copy(characteristics_panel[0])\n",
    "    if residuals is not None:\n",
    "        last_resid = np.copy(residuals[0])\n",
    "\n",
    "    lag_amount = np.zeros_like(last_val)\n",
    "    lag_amount[:] = np.nan\n",
    "    if residuals is None:\n",
    "        sufficient_statistics = np.zeros((T,N,L, 1), dtype=float)\n",
    "    else:\n",
    "        sufficient_statistics = np.zeros((T,N,L, 2), dtype=float)\n",
    "    sufficient_statistics[:,:,:,:] = np.nan\n",
    "    deltas = np.copy(sufficient_statistics[:,:,:,0])\n",
    "    for t in range(1, T):\n",
    "        lag_amount += 1\n",
    "        sufficient_statistics[t, :, :, 0] = np.copy(last_val)\n",
    "        deltas[t] = np.copy(lag_amount)\n",
    "        present_t = ~np.isnan(characteristics_panel[t])\n",
    "        last_val[present_t] = np.copy(characteristics_panel[t, present_t])\n",
    "        if residuals is not None:\n",
    "            sufficient_statistics[t, :, :, 1] = np.copy(last_resid)\n",
    "            last_resid[present_t] = np.copy(residuals[t, present_t])\n",
    "        lag_amount[present_t] = 0\n",
    "        if max_delta is not None:\n",
    "            last_val[lag_amount >= max_delta] = np.nan\n",
    "    return sufficient_statistics, deltas\n",
    "\n",
    "\n",
    "def impute_chars(char_data, imputed_chars, residuals=None, \n",
    "                 suff_stat_method='None', constant_beta=False):\n",
    "    \"\"\"\n",
    "    run the imputation for a given configuration\n",
    "    Parameters\n",
    "    ----------\n",
    "        char_data : the time series panel, T x N x L\n",
    "        imputed_chars: the cross-sectional imputation of the time series panel\n",
    "        residuals=None : Optional, residuals T x N x L, the residuals the factor model applied to the time\n",
    "                        series panel\n",
    "        suff_stat_method=None : Optional, the type of information to add to the cross sectional panel in the \n",
    "                        imputation\n",
    "        constant_beta=False: whether or not to allow time variation in the loadings of the model\n",
    "    \"\"\"\n",
    "    if suff_stat_method == 'last_val':\n",
    "        suff_stats, _ = get_sufficient_statistics_last_val(char_data, max_delta=None,\n",
    "                                                                           residuals=residuals)\n",
    "        if len(suff_stats.shape) == 3:\n",
    "            suff_stats = np.expand_dims(suff_stats, axis=3)\n",
    "                \n",
    "    elif suff_stat_method == 'None':\n",
    "        suff_stats = None\n",
    "            \n",
    "    if suff_stats is None:\n",
    "        return imputed_chars\n",
    "    else:\n",
    "        return impute_beta_combined_regression(\n",
    "            char_data, imputed_chars, sufficient_statistics=suff_stats, \n",
    "            constant_beta=constant_beta\n",
    "        )\n",
    "\n",
    "def impute_beta_combined_regression(characteristics_panel, xs_imps, sufficient_statistics=None, \n",
    "                                    constant_beta=False, get_betas=False, gamma_ts=None, use_factors=False, reg=None):\n",
    "    \"\"\"\n",
    "    run the imputation regression for a given configuration\n",
    "    Parameters\n",
    "    ----------\n",
    "        char_data : the time series panel, T x N x L\n",
    "        xs_imps: the cross-sectional imputation of the time series panel\n",
    "        sufficient_statistics=None : Optional, the information to add to the cross sectaial panel in the imputation\n",
    "        constant_beta=False: whether or not to allow time variation in the loadings of the model\n",
    "        get_betas=False: whether or not to return the learned betas\n",
    "        \n",
    "    \"\"\"\n",
    "    T, N, L = characteristics_panel.shape\n",
    "    K = 0\n",
    "    if xs_imps is not None:\n",
    "        K += 1\n",
    "    if sufficient_statistics is not None:\n",
    "        K += sufficient_statistics.shape[3]\n",
    "\n",
    "    betas = np.zeros((T, L, K))\n",
    "    imputed_data = np.copy(characteristics_panel)\n",
    "    imputed_data[:,:,:]=np.nan\n",
    "    \n",
    "    for l in range(L):\n",
    "        fit_suff_stats = []\n",
    "        fit_tgts = []\n",
    "        inds = []\n",
    "        curr_ind = 0\n",
    "        all_suff_stats = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            inds.append(curr_ind)\n",
    "            \n",
    "            if xs_imps is not None:\n",
    "                suff_stat = np.concatenate([xs_imps[t,:,l:l+1], sufficient_statistics[t,:,l]], axis=1)\n",
    "            else:\n",
    "                suff_stat = sufficient_statistics[t,:,l]\n",
    "            \n",
    "            available_for_imputation = np.all(~np.isnan(suff_stat), axis=1)\n",
    "            available_for_fit = np.logical_and(~np.isnan(characteristics_panel[t,:,l]),\n",
    "                                                  available_for_imputation)\n",
    "            all_suff_stats.append(suff_stat)\n",
    "\n",
    "            fit_suff_stats.append(suff_stat[available_for_fit, :])\n",
    "            fit_tgts.append(characteristics_panel[t,available_for_fit,l])\n",
    "            curr_ind += np.sum(available_for_fit)\n",
    "        \n",
    "        \n",
    "        inds.append(curr_ind)\n",
    "        fit_suff_stats = np.concatenate(fit_suff_stats, axis=0)\n",
    "        fit_tgts = np.concatenate(fit_tgts, axis=0)\n",
    "        \n",
    "        if constant_beta:\n",
    "\n",
    "            beta = np.linalg.lstsq(fit_suff_stats, fit_tgts, rcond=None)[0]\n",
    "                \n",
    "            betas[:,l,:] = beta.reshape(1, -1)\n",
    "        else:\n",
    "            for t in range(T):\n",
    "                beta_l_t = np.linalg.lstsq(fit_suff_stats[inds[t]:inds[t+1]],\n",
    "                                       fit_tgts[inds[t]:inds[t+1]], rcond=None)[0]\n",
    "                betas[t,l,:] = beta_l_t\n",
    "                if np.any(np.isnan(beta_l_t)):\n",
    "                    print(\"should be no nans, t=\", t,)\n",
    "                \n",
    "        for t in range(T):\n",
    "            beta_l_t = betas[t,l]\n",
    "            suff_stat = all_suff_stats[t]\n",
    "            available_for_imputation = np.all(~np.isnan(suff_stat), axis=1)\n",
    "            imputed_data[t,available_for_imputation,l] = suff_stat[available_for_imputation,:] @ beta_l_t\n",
    "            \n",
    "    if get_betas:\n",
    "        return imputed_data, betas\n",
    "    else:\n",
    "        return imputed_data\n",
    "\n",
    "\n",
    "\n",
    "def get_oos_estimates_given_loadings(chars, reg, Lmbda, time_varying_lmbda=False, get_factors=False):\n",
    "    \"\"\"\n",
    "    Generate the finite-sample correction to the cross-sectionally imputed data\n",
    "    Parameters\n",
    "    ----------\n",
    "        chars : the time series panel, T x N x L\n",
    "        Lmbda : the loadings in the Xiong - Pelger model\n",
    "        time_varying_lmbda=False: whether or the loadings are time varying\n",
    "        get_factors=False: whether or not to return the factors, or the imputed values        \n",
    "    \"\"\"\n",
    "    C = chars.shape[-1]\n",
    "    def impute_t(t_chars, reg, C, Lmbda, get_factors=False):\n",
    "        if not get_factors:\n",
    "            imputation = np.copy(t_chars) * np.nan\n",
    "        else:\n",
    "            imputation = np.zeros((t_chars.shape[0], t_chars.shape[1], Lmbda.shape[1])) * np.nan\n",
    "        mask = ~np.isnan(t_chars)\n",
    "        net_mask = np.sum(mask, axis=1)\n",
    "        K = Lmbda.shape[1]\n",
    "        for n in range(t_chars.shape[0]):\n",
    "            if net_mask[n] == 1:\n",
    "                imputation[n,:] = 0\n",
    "            elif net_mask[n] > 1:\n",
    "                for i in range(C):\n",
    "                    tmp = mask[n, i]\n",
    "                    mask[n,i] = False\n",
    "                    y = t_chars[n, mask[n]]\n",
    "                    X = Lmbda[mask[n], :]\n",
    "                    L = np.eye(K) * reg\n",
    "                    params = np.linalg.lstsq(X.T @ X + L, X.T @ y, rcond=None)[0]\n",
    "                    if get_factors:\n",
    "                        imputation[n,i] = params\n",
    "                    else:\n",
    "                        imputation[n,i] = Lmbda[i] @ params\n",
    "                    \n",
    "                    mask[n,i] = tmp\n",
    "        return np.expand_dims(imputation, axis=0)\n",
    "    chars = [chars_t for chars_t in chars]\n",
    "    \n",
    "    if time_varying_lmbda:\n",
    "        imputation = list(Parallel(n_jobs=60)(delayed(impute_t)(chars_t, reg, C, l, get_factors=get_factors) \n",
    "                                              for chars_t, l in zip(chars, Lmbda)))\n",
    "    else:\n",
    "        imputation = list(Parallel(n_jobs=60)(delayed(impute_t)(chars_t, reg, C, Lmbda, get_factors=get_factors)\n",
    "                                              for chars_t in chars))\n",
    "    return np.concatenate(imputation, axis=0)\n",
    "\n",
    "\n",
    "def simple_impute(char_panel):\n",
    "    \"\"\" \n",
    "    Imputes using the last value of the characteristic time series - the forward filling\n",
    "    \n",
    "    \"\"\"\n",
    "    imputed_panel = np.copy(char_panel)\n",
    "    imputed_panel[:,:,:] = np.nan\n",
    "    imputed_panel[0] = np.copy(char_panel[0])\n",
    "\n",
    "    for t in range(1, imputed_panel.shape[0]):\n",
    "        present_t_l = ~np.isnan(char_panel[t-1])\n",
    "        imputed_t_1 = ~np.isnan(imputed_panel[t-1])\n",
    "        imputed_panel[t, present_t_l] = char_panel[t-1, present_t_l]\n",
    "        imputed_panel[t, np.logical_and(~present_t_l,\n",
    "                                        imputed_t_1)] = imputed_panel[t-1,\n",
    "                                                                      np.logical_and(~present_t_l, imputed_t_1)]\n",
    "        imputed_panel[t, ~np.logical_or(imputed_t_1, present_t_l)] = np.nan \n",
    "\n",
    "    return imputed_panel\n",
    "\n",
    "\n",
    "def xs_median_impute(char_panel):\n",
    "    \"\"\" \n",
    "    Imputes using the cross-sectional median for each time period and characteristic\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    imputed_panel = np.copy(char_panel)\n",
    "    for t in range(imputed_panel.shape[0]):\n",
    "        for c in range(imputed_panel.shape[2]):\n",
    "            present_t_1 = ~np.isnan(char_panel[t,:,c])\n",
    "            imputed_panel[t,:,c] = np.median(char_panel[t, present_t_1, c])\n",
    "    return imputed_panel\n",
    "\n",
    "def impute_em(X, max_iter=50, eps=1e-08):\n",
    "    \"\"\" \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    nr, nc = X.shape\n",
    "    C = np.isnan(X) == False \n",
    "\n",
    "    # Collect M_i and O_i's \n",
    "    one_to_nc = np.arange(1, nc+1, step=1)\n",
    "    M = one_to_nc * (C==False) - 1\n",
    "    O = one_to_nc * C - 1\n",
    "\n",
    "    # Generate Mu_0 and Sigma_0\n",
    "    Mu = np.nanmean(X, axis=0)\n",
    "    observed_rows = np.where(np.isnan(sum(X.T)) == False)[0]\n",
    "    S = np.cov(X[observed_rows, ].T)\n",
    "    if np.isnan(S).any():\n",
    "        S = np.diag(np.nanvar(X, axis = 0))\n",
    "\n",
    "    # Start updating\n",
    "    Mu_tilde, S_tilde = {}, {}\n",
    "    X_tilde = X.copy()\n",
    "    no_conv = True \n",
    "    iteration = 0 \n",
    "    while no_conv and iteration < max_iter:\n",
    "        for i in range(nr):\n",
    "            S_tilde[i] = np.zeros(nc ** 2).reshape(nc, nc)\n",
    "            if set(O[i, ]) != set(one_to_nc - 1): # missing component exists\n",
    "                M_i, O_i = M[i, ][M[i, ] != -1], O[i,][O[i, ] != -1]\n",
    "                S_MM = S[np.ix_(M_i, M_i)]\n",
    "                S_MO = S[np.ix_(M_i, O_i)]\n",
    "                S_OM = S_MO.T \n",
    "                S_OO = S[np.ix_(O_i, O_i)]\n",
    "                Mu_tilde[i] = Mu[np.ix_(M_i)] +\\\n",
    "                    S_MO @ np.linalg.inv(S_OO) @\\\n",
    "                    (X_tilde[i, O_i]) - Mu[np.ix_(O_i)]\n",
    "                X_tilde[i, M_i] = Mu_tilde[i]\n",
    "                S_MM_O = S_MM - S_MO @ np.linalg.inv(S_OO) @ S_OM\n",
    "                S_tilde[i][np.ix_(M_i, M_i)] = S_MM_O\n",
    "        Mu_new = np.mean(X_tilde, axis=0)\n",
    "        S_new = np.cov(X_tilde.T, bias=1) +\\\n",
    "            reduce(np.add, S_tilde.values()) / nr \n",
    "        no_conv = \\\n",
    "            np.linalg.norm(Mu - Mu_new) >= eps or\\\n",
    "            np.linalg.norm(S - S_new, ord=2) >= eps \n",
    "        \n",
    "        Mu = Mu_new\n",
    "        S = S_new \n",
    "        iteration += 1 \n",
    "\n",
    "    result = {\n",
    "        'mu': Mu,\n",
    "        'Sigma': S,\n",
    "        'X_imputed': X_tilde,\n",
    "        'C': C,\n",
    "        'iteration': iteration\n",
    "    }\n",
    "\n",
    "    return result \n",
    "\n",
    "def project_percentile_data(observed_data, percentile_data):\n",
    "    # Flatten the input arrays if necessary\n",
    "    observed_data = np.asarray(observed_data).flatten()\n",
    "    percentile_data = np.asarray(percentile_data).flatten()\n",
    "\n",
    "    # Fit the KDE to the observed data\n",
    "    kde = KernelDensity().fit(observed_data.reshape(-1,1))\n",
    "\n",
    "    # Estimate the CDF of the observed data\n",
    "    observed_cdf = np.cumsum(np.exp(kde.score_samples(observed_data.reshape(-1,1))))\n",
    "    observed_cdf /= observed_cdf[-1]\n",
    "\n",
    "    # Map the projectile data to the observed data space\n",
    "    # projected_data = np.interp(percentile_data, observed_cdf, observed_data) # simple way which uses linear interpolation\n",
    "\n",
    "    # Fit a KNN regressor to map the percentile data\n",
    "    knn = KNeighborsRegressor(n_neighbors=5)\n",
    "    knn.fit(np.array(observed_cdf).reshape(-1,1), observed_data.reshape(-1,1))\n",
    "\n",
    "    # Map the percentile data to the observed data space using KNN\n",
    "    projected_data = (knn.predict(percentile_data.reshape(-1,1))).reshape(-1,)\n",
    "\n",
    "    return projected_data\n",
    "\n",
    "\n",
    "def project_percentile_data_with_knn(observed_data, x_percentile_data, percentile_data):\n",
    "    # Flatten the input arrays if necessary\n",
    "    observed_data = np.asarray(observed_data).flatten()\n",
    "    x_percentile_data = np.asarray(x_percentile_data).flatten()\n",
    "    percentile_data = np.asarray(percentile_data).flatten()\n",
    "\n",
    "    # Fit a KNN regressor to map the percentile data\n",
    "    knn = KNeighborsRegressor(n_neighbors=25)\n",
    "    knn.fit(np.array(x_percentile_data).reshape(-1,1), observed_data.reshape(-1,1))\n",
    "\n",
    "    input_percentile_data = percentile_data.copy()\n",
    "    # get missing mask\n",
    "    missing_mask = np.isnan(input_percentile_data)\n",
    "\n",
    "    input_percentile_data = np.nan_to_num(input_percentile_data) # convert all nan to zero\n",
    "\n",
    "    # Map the percentile data to the observed data space using KNN\n",
    "    projected_data = (knn.predict(input_percentile_data.reshape(-1,1)))\n",
    "\n",
    "    # now we return the nan back to the predictions\n",
    "    projected_data[missing_mask] = np.nan\n",
    "\n",
    "    return projected_data.reshape(-1,)\n",
    "\n",
    "\n",
    "def invert_cross_sectional_percentiles_with_knn(percentile_panel, partially_observed_panel):\n",
    "    T, N, L = percentile_panel.shape\n",
    "    inverted_panel = np.zeros((T,N,L))\n",
    "    for t in range(T):\n",
    "        # Extract the cross-sectional data at time t \n",
    "        for l in range(L): # Looping through the periodic characteristics\n",
    "            observed_data = partially_observed_panel[t,:,l] # might contain missing values\n",
    "            if np.isnan(observed_data).any():\n",
    "                missing_mask = np.isnan(observed_data)\n",
    "                observed_data = observed_data[~missing_mask] # getting only the fully observed_data \n",
    "            else: # no missing components\n",
    "                observed_data = observed_data # do nothing\n",
    "\n",
    "\n",
    "            percentile_data = percentile_panel[t,:,l]\n",
    "\n",
    "            x_percentile_data = percentile_data.copy()\n",
    "            x_percentile_data = x_percentile_data[~missing_mask] # get corresponding percentile of fully observed data\n",
    "\n",
    "\n",
    "            # look for more missing values in x_percentile_data and effect it in both x_percentile_data and observed data\n",
    "            more_missing_mask  = np.isnan(x_percentile_data)\n",
    "\n",
    "            x_percentile_data_ = x_percentile_data.copy()\n",
    "            x_percentile_data_ = x_percentile_data_[~more_missing_mask]\n",
    "\n",
    "            observed_data = observed_data[~more_missing_mask]\n",
    "\n",
    "            input_missing_mask = np.isnan(percentile_data)\n",
    "            percentile_data_ = percentile_data.copy()\n",
    "            percentile_data_ = percentile_data[~input_missing_mask]\n",
    "\n",
    "            inverted_panel[t,:,l][~input_missing_mask] = project_percentile_data_with_knn(observed_data, x_percentile_data_, percentile_data_)\n",
    "\n",
    "    # fetch the mask and only fill those places\n",
    "    mask = np.isnan(partially_observed_panel)\n",
    "\n",
    "    full_data = partially_observed_panel.copy() # just initialize\n",
    "\n",
    "    full_data[mask] = inverted_panel[mask]\n",
    "\n",
    "    return full_data \n",
    "\n",
    "\n",
    "\n",
    "# sort dataframe\n",
    "\n",
    "def sort_dataframe(df, N_column_name):\n",
    "    \"\"\" \n",
    "    code to sort the dataframe based on the column names, N column and the date\n",
    "    - helps with easy reproducibility of the code\n",
    "    \"\"\"\n",
    "    columns_to_exclude = ['date', N_column_name]\n",
    "    sorted_columns = sorted([col for col in df.columns if col not in columns_to_exclude])\n",
    "    sorted_columns = ['date', N_column_name] + sorted_columns \n",
    "    sorted_df = df[sorted_columns].sort_values(by=['date', N_column_name], ascending=True)\n",
    "    return sorted_df\n",
    "\n",
    "\n",
    "# compute performance metrics\n",
    "\n",
    "def compute_rmse(truth_panel, predicted_panel):\n",
    "    \"\"\" \n",
    "    Compute root mean squared error\n",
    "    \"\"\"\n",
    "    resids = truth_panel - predicted_panel\n",
    "    error = np.sqrt(np.nanmean(np.square(resids)))\n",
    "    return error \n",
    "\n",
    "\n",
    "def compute_r2(truth_panel, predicted_panel):\n",
    "    \"\"\" \n",
    "    Compute R^2\n",
    "    \"\"\"\n",
    "    imputed = predicted_panel\n",
    "    tgt = np.copy(truth_panel)\n",
    "    tgt[np.isnan(imputed)] = np.nan \n",
    "\n",
    "    overall_r2 = np.nanmean(1 - np.nansum(np.square(tgt - imputed), axis=(1,2)) /\n",
    "                            np.nansum(np.square(tgt), axis=(1,2)), axis=0)\n",
    "    return overall_r2\n",
    " \n",
    "\n",
    "\n",
    "# Mask generator\n",
    "\n",
    "def get_random_masks(present_chars, p):\n",
    "    \"\"\" \n",
    "    get a fully random mask over observed characteristics\n",
    "    \"\"\"\n",
    "    flipped = np.random.binomial(1,p, size=present_chars.shape) == 1\n",
    "    flipped = np.logical_and(~np.isnan(present_chars), flipped)\n",
    "    return flipped \n",
    "\n",
    "def generate_MAR_missing_data(rank_chars):\n",
    "    \"\"\" \n",
    "    Generate a MAR masked dataset\n",
    "    --- fixing the value of p at 0.1 # can experiment with different values later\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    T,N,L = rank_chars.shape \n",
    "    update_chars = np.copy(rank_chars)\n",
    "\n",
    "    random_nan_mask = get_random_masks(update_chars, p=0.1)\n",
    "    print(random_nan_mask.shape)\n",
    "    print(np.max(np.sum(random_nan_mask, axis=2)),\n",
    "          np.sum(random_nan_mask, axis=(0,1)) / (np.sum(~np.isnan(update_chars), axis=(0,1))))\n",
    "    masked_chars = np.copy(update_chars)\n",
    "    masked_chars[random_nan_mask] = np.nan \n",
    "\n",
    "    masked_lagged_chars = np.copy(rank_chars)\n",
    "    only_missing_chars = np.copy(rank_chars)\n",
    "    only_missing_chars[:,:,:] = np.nan \n",
    "\n",
    "    for c in range(L):\n",
    "        for t in range(random_nan_mask.shape[0]):\n",
    "            missing = random_nan_mask[t,:,c]\n",
    "            only_missing_chars[t,missing,c] = np.copy(masked_lagged_chars[t,missing,c])\n",
    "            masked_lagged_chars[t,missing,c] = np.nan \n",
    "    only_mimissing_chars = np.copy(rank_chars)\n",
    "    only_mimissing_chars[~random_nan_mask] = np.nan \n",
    "\n",
    "    return masked_lagged_chars, only_mimissing_chars \n",
    "\n",
    "\n",
    "\n",
    "# function to generate simulated data\n",
    "\n",
    "def simulate_nan(X, nan_rate):\n",
    "    \"\"\" \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Create C matrix; entry is False if missing, and True if observed\n",
    "    X_complete = X.copy()\n",
    "    nr, nc = X_complete.shape\n",
    "    C = np.random.random(nr * nc).reshape(nr, nc) > nan_rate\n",
    "\n",
    "    # Check for which i's we have all components become missing\n",
    "    checker = np.where(sum(C.T) == 0)[0]\n",
    "    if len(checker) == 0:\n",
    "        # Every X_i has at least one component that is observed,\n",
    "        # which is what we want\n",
    "        X_complete[C == False] = np.nan \n",
    "    else:\n",
    "        # Otherwise, randomly \"revive\" some components in such X_i's \n",
    "        for index in checker:\n",
    "            reviving_components = np.random.choice(\n",
    "                nc,\n",
    "                int(np.ceil(nc * np.random.random())),\n",
    "                replace=False\n",
    "            )\n",
    "            C[index, np.ix_(reviving_components)] = True\n",
    "        X_complete[C == False] = np.nan \n",
    "\n",
    "    result = {\n",
    "        'X': X_complete,\n",
    "        'C': C,\n",
    "        'nan_rate': nan_rate,\n",
    "        'nan_rate_actual': np.sum(C == False) / (nr * nc)\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/example_data.fthr\"\n",
    "# percentile_rank_chars, chars, date_vals, permnos = get_data_panel(\n",
    "#     path=data_path, computstat_data_present_filter=True,start_date=19770000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_feather(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2ME</th>\n",
       "      <th>AC</th>\n",
       "      <th>AT</th>\n",
       "      <th>ATO</th>\n",
       "      <th>B2M</th>\n",
       "      <th>BETA_d</th>\n",
       "      <th>BETA_m</th>\n",
       "      <th>C2A</th>\n",
       "      <th>CF2B</th>\n",
       "      <th>CF2P</th>\n",
       "      <th>...</th>\n",
       "      <th>S2P</th>\n",
       "      <th>SGA2S</th>\n",
       "      <th>SPREAD</th>\n",
       "      <th>SUV</th>\n",
       "      <th>TURN</th>\n",
       "      <th>VAR</th>\n",
       "      <th>return</th>\n",
       "      <th>date</th>\n",
       "      <th>permno</th>\n",
       "      <th>monthly_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.341989</td>\n",
       "      <td>0.073275</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>0.269502</td>\n",
       "      <td>-0.170260</td>\n",
       "      <td>-0.276312</td>\n",
       "      <td>-0.418199</td>\n",
       "      <td>0.170995</td>\n",
       "      <td>0.277532</td>\n",
       "      <td>0.155130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056347</td>\n",
       "      <td>-0.171998</td>\n",
       "      <td>-0.265957</td>\n",
       "      <td>0.178494</td>\n",
       "      <td>-0.024265</td>\n",
       "      <td>-0.087374</td>\n",
       "      <td>-0.100016</td>\n",
       "      <td>20200131.0</td>\n",
       "      <td>10026.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.284909</td>\n",
       "      <td>0.372676</td>\n",
       "      <td>-0.426805</td>\n",
       "      <td>0.400604</td>\n",
       "      <td>-0.264821</td>\n",
       "      <td>-0.394166</td>\n",
       "      <td>-0.489295</td>\n",
       "      <td>-0.007839</td>\n",
       "      <td>0.430341</td>\n",
       "      <td>-0.117820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271176</td>\n",
       "      <td>-0.250800</td>\n",
       "      <td>0.301578</td>\n",
       "      <td>-0.290490</td>\n",
       "      <td>-0.090963</td>\n",
       "      <td>0.281565</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>20200131.0</td>\n",
       "      <td>10028.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.038462</td>\n",
       "      <td>-0.033880</td>\n",
       "      <td>0.119584</td>\n",
       "      <td>0.413689</td>\n",
       "      <td>-0.045076</td>\n",
       "      <td>0.087804</td>\n",
       "      <td>-0.076997</td>\n",
       "      <td>0.039441</td>\n",
       "      <td>0.350625</td>\n",
       "      <td>0.129602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294991</td>\n",
       "      <td>-0.460744</td>\n",
       "      <td>-0.100765</td>\n",
       "      <td>-0.376418</td>\n",
       "      <td>0.057495</td>\n",
       "      <td>-0.253961</td>\n",
       "      <td>-0.075643</td>\n",
       "      <td>20200131.0</td>\n",
       "      <td>10032.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.221705</td>\n",
       "      <td>0.043019</td>\n",
       "      <td>-0.421665</td>\n",
       "      <td>0.262204</td>\n",
       "      <td>-0.067859</td>\n",
       "      <td>-0.462474</td>\n",
       "      <td>-0.349026</td>\n",
       "      <td>0.177119</td>\n",
       "      <td>0.096272</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102259</td>\n",
       "      <td>-0.225502</td>\n",
       "      <td>-0.244442</td>\n",
       "      <td>0.244871</td>\n",
       "      <td>-0.209539</td>\n",
       "      <td>-0.393663</td>\n",
       "      <td>-0.098592</td>\n",
       "      <td>20200131.0</td>\n",
       "      <td>10044.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.077658</td>\n",
       "      <td>-0.493697</td>\n",
       "      <td>-0.041983</td>\n",
       "      <td>0.290891</td>\n",
       "      <td>-0.438021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181856</td>\n",
       "      <td>-0.123224</td>\n",
       "      <td>-0.486264</td>\n",
       "      <td>-0.056456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011834</td>\n",
       "      <td>-0.131909</td>\n",
       "      <td>0.046259</td>\n",
       "      <td>-0.186270</td>\n",
       "      <td>-0.115176</td>\n",
       "      <td>20200131.0</td>\n",
       "      <td>10051.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A2ME        AC        AT       ATO       B2M    BETA_d    BETA_m  \\\n",
       "0 -0.341989  0.073275 -0.000122  0.269502 -0.170260 -0.276312 -0.418199   \n",
       "1 -0.284909  0.372676 -0.426805  0.400604 -0.264821 -0.394166 -0.489295   \n",
       "2 -0.038462 -0.033880  0.119584  0.413689 -0.045076  0.087804 -0.076997   \n",
       "3 -0.221705  0.043019 -0.421665  0.262204 -0.067859 -0.462474 -0.349026   \n",
       "4 -0.077658 -0.493697 -0.041983  0.290891 -0.438021       NaN  0.181856   \n",
       "\n",
       "        C2A      CF2B      CF2P  ...       S2P     SGA2S    SPREAD       SUV  \\\n",
       "0  0.170995  0.277532  0.155130  ... -0.056347 -0.171998 -0.265957  0.178494   \n",
       "1 -0.007839  0.430341 -0.117820  ...  0.271176 -0.250800  0.301578 -0.290490   \n",
       "2  0.039441  0.350625  0.129602  ...  0.294991 -0.460744 -0.100765 -0.376418   \n",
       "3  0.177119  0.096272  0.011537  ...  0.102259 -0.225502 -0.244442  0.244871   \n",
       "4 -0.123224 -0.486264 -0.056456  ...  0.245642       NaN -0.011834 -0.131909   \n",
       "\n",
       "       TURN       VAR    return        date   permno  monthly_update  \n",
       "0 -0.024265 -0.087374 -0.100016  20200131.0  10026.0             0.0  \n",
       "1 -0.090963  0.281565  0.607407  20200131.0  10028.0             0.0  \n",
       "2  0.057495 -0.253961 -0.075643  20200131.0  10032.0             0.0  \n",
       "3 -0.209539 -0.393663 -0.098592  20200131.0  10044.0             0.0  \n",
       "4  0.046259 -0.186270 -0.115176  20200131.0  10051.0             0.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2ME</th>\n",
       "      <th>AC</th>\n",
       "      <th>AT</th>\n",
       "      <th>ATO</th>\n",
       "      <th>B2M</th>\n",
       "      <th>BETA_d</th>\n",
       "      <th>BETA_m</th>\n",
       "      <th>C2A</th>\n",
       "      <th>CF2B</th>\n",
       "      <th>CF2P</th>\n",
       "      <th>...</th>\n",
       "      <th>S2P</th>\n",
       "      <th>SGA2S</th>\n",
       "      <th>SPREAD</th>\n",
       "      <th>SUV</th>\n",
       "      <th>TURN</th>\n",
       "      <th>VAR</th>\n",
       "      <th>return</th>\n",
       "      <th>date</th>\n",
       "      <th>permno</th>\n",
       "      <th>monthly_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.341989</td>\n",
       "      <td>0.073275</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>0.269502</td>\n",
       "      <td>-0.170260</td>\n",
       "      <td>-0.276312</td>\n",
       "      <td>-0.418199</td>\n",
       "      <td>0.170995</td>\n",
       "      <td>0.277532</td>\n",
       "      <td>0.155130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056347</td>\n",
       "      <td>-0.171998</td>\n",
       "      <td>-0.265957</td>\n",
       "      <td>0.178494</td>\n",
       "      <td>-0.024265</td>\n",
       "      <td>-0.087374</td>\n",
       "      <td>-0.100016</td>\n",
       "      <td>20200131.0</td>\n",
       "      <td>10026.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.284909</td>\n",
       "      <td>0.372676</td>\n",
       "      <td>-0.426805</td>\n",
       "      <td>0.400604</td>\n",
       "      <td>-0.264821</td>\n",
       "      <td>-0.394166</td>\n",
       "      <td>-0.489295</td>\n",
       "      <td>-0.007839</td>\n",
       "      <td>0.430341</td>\n",
       "      <td>-0.117820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271176</td>\n",
       "      <td>-0.250800</td>\n",
       "      <td>0.301578</td>\n",
       "      <td>-0.290490</td>\n",
       "      <td>-0.090963</td>\n",
       "      <td>0.281565</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>20200131.0</td>\n",
       "      <td>10028.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.038462</td>\n",
       "      <td>-0.033880</td>\n",
       "      <td>0.119584</td>\n",
       "      <td>0.413689</td>\n",
       "      <td>-0.045076</td>\n",
       "      <td>0.087804</td>\n",
       "      <td>-0.076997</td>\n",
       "      <td>0.039441</td>\n",
       "      <td>0.350625</td>\n",
       "      <td>0.129602</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294991</td>\n",
       "      <td>-0.460744</td>\n",
       "      <td>-0.100765</td>\n",
       "      <td>-0.376418</td>\n",
       "      <td>0.057495</td>\n",
       "      <td>-0.253961</td>\n",
       "      <td>-0.075643</td>\n",
       "      <td>20200131.0</td>\n",
       "      <td>10032.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.221705</td>\n",
       "      <td>0.043019</td>\n",
       "      <td>-0.421665</td>\n",
       "      <td>0.262204</td>\n",
       "      <td>-0.067859</td>\n",
       "      <td>-0.462474</td>\n",
       "      <td>-0.349026</td>\n",
       "      <td>0.177119</td>\n",
       "      <td>0.096272</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102259</td>\n",
       "      <td>-0.225502</td>\n",
       "      <td>-0.244442</td>\n",
       "      <td>0.244871</td>\n",
       "      <td>-0.209539</td>\n",
       "      <td>-0.393663</td>\n",
       "      <td>-0.098592</td>\n",
       "      <td>20200131.0</td>\n",
       "      <td>10044.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.077658</td>\n",
       "      <td>-0.493697</td>\n",
       "      <td>-0.041983</td>\n",
       "      <td>0.290891</td>\n",
       "      <td>-0.438021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181856</td>\n",
       "      <td>-0.123224</td>\n",
       "      <td>-0.486264</td>\n",
       "      <td>-0.056456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011834</td>\n",
       "      <td>-0.131909</td>\n",
       "      <td>0.046259</td>\n",
       "      <td>-0.186270</td>\n",
       "      <td>-0.115176</td>\n",
       "      <td>20200131.0</td>\n",
       "      <td>10051.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55567</th>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.284116</td>\n",
       "      <td>0.167874</td>\n",
       "      <td>-0.186449</td>\n",
       "      <td>-0.446821</td>\n",
       "      <td>0.447905</td>\n",
       "      <td>0.403696</td>\n",
       "      <td>-0.228784</td>\n",
       "      <td>0.462054</td>\n",
       "      <td>0.326508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236594</td>\n",
       "      <td>0.126663</td>\n",
       "      <td>0.057781</td>\n",
       "      <td>-0.409368</td>\n",
       "      <td>0.294199</td>\n",
       "      <td>0.186148</td>\n",
       "      <td>0.109665</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>93423.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55568</th>\n",
       "      <td>0.026710</td>\n",
       "      <td>0.365112</td>\n",
       "      <td>-0.156763</td>\n",
       "      <td>0.131431</td>\n",
       "      <td>0.155547</td>\n",
       "      <td>-0.020664</td>\n",
       "      <td>0.106151</td>\n",
       "      <td>0.155583</td>\n",
       "      <td>-0.154514</td>\n",
       "      <td>0.173616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165094</td>\n",
       "      <td>-0.045670</td>\n",
       "      <td>-0.238260</td>\n",
       "      <td>0.201405</td>\n",
       "      <td>-0.213858</td>\n",
       "      <td>-0.084906</td>\n",
       "      <td>0.076239</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>93426.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55569</th>\n",
       "      <td>-0.185037</td>\n",
       "      <td>0.082414</td>\n",
       "      <td>0.051449</td>\n",
       "      <td>0.402191</td>\n",
       "      <td>-0.041939</td>\n",
       "      <td>-0.333527</td>\n",
       "      <td>-0.158484</td>\n",
       "      <td>0.243176</td>\n",
       "      <td>0.248512</td>\n",
       "      <td>0.035865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128848</td>\n",
       "      <td>-0.477830</td>\n",
       "      <td>-0.289134</td>\n",
       "      <td>-0.049415</td>\n",
       "      <td>-0.174724</td>\n",
       "      <td>-0.358491</td>\n",
       "      <td>0.135851</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>93427.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55570</th>\n",
       "      <td>0.148779</td>\n",
       "      <td>-0.433186</td>\n",
       "      <td>-0.287681</td>\n",
       "      <td>-0.025981</td>\n",
       "      <td>0.175127</td>\n",
       "      <td>-0.445576</td>\n",
       "      <td>-0.313056</td>\n",
       "      <td>-0.371960</td>\n",
       "      <td>-0.167659</td>\n",
       "      <td>-0.368950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224181</td>\n",
       "      <td>0.044783</td>\n",
       "      <td>0.308011</td>\n",
       "      <td>0.440047</td>\n",
       "      <td>-0.345304</td>\n",
       "      <td>0.119650</td>\n",
       "      <td>0.122605</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>93434.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55571</th>\n",
       "      <td>-0.481629</td>\n",
       "      <td>0.209108</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.151808</td>\n",
       "      <td>-0.422649</td>\n",
       "      <td>0.352445</td>\n",
       "      <td>0.355678</td>\n",
       "      <td>0.183375</td>\n",
       "      <td>-0.247024</td>\n",
       "      <td>-0.135890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325720</td>\n",
       "      <td>-0.281259</td>\n",
       "      <td>0.140654</td>\n",
       "      <td>0.337939</td>\n",
       "      <td>0.421501</td>\n",
       "      <td>0.077082</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>93436.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55572 rows  49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A2ME        AC        AT       ATO       B2M    BETA_d    BETA_m  \\\n",
       "0     -0.341989  0.073275 -0.000122  0.269502 -0.170260 -0.276312 -0.418199   \n",
       "1     -0.284909  0.372676 -0.426805  0.400604 -0.264821 -0.394166 -0.489295   \n",
       "2     -0.038462 -0.033880  0.119584  0.413689 -0.045076  0.087804 -0.076997   \n",
       "3     -0.221705  0.043019 -0.421665  0.262204 -0.067859 -0.462474 -0.349026   \n",
       "4     -0.077658 -0.493697 -0.041983  0.290891 -0.438021       NaN  0.181856   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "55567  0.004230  0.284116  0.167874 -0.186449 -0.446821  0.447905  0.403696   \n",
       "55568  0.026710  0.365112 -0.156763  0.131431  0.155547 -0.020664  0.106151   \n",
       "55569 -0.185037  0.082414  0.051449  0.402191 -0.041939 -0.333527 -0.158484   \n",
       "55570  0.148779 -0.433186 -0.287681 -0.025981  0.175127 -0.445576 -0.313056   \n",
       "55571 -0.481629  0.209108  0.455556  0.151808 -0.422649  0.352445  0.355678   \n",
       "\n",
       "            C2A      CF2B      CF2P  ...       S2P     SGA2S    SPREAD  \\\n",
       "0      0.170995  0.277532  0.155130  ... -0.056347 -0.171998 -0.265957   \n",
       "1     -0.007839  0.430341 -0.117820  ...  0.271176 -0.250800  0.301578   \n",
       "2      0.039441  0.350625  0.129602  ...  0.294991 -0.460744 -0.100765   \n",
       "3      0.177119  0.096272  0.011537  ...  0.102259 -0.225502 -0.244442   \n",
       "4     -0.123224 -0.486264 -0.056456  ...  0.245642       NaN -0.011834   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "55567 -0.228784  0.462054  0.326508  ... -0.236594  0.126663  0.057781   \n",
       "55568  0.155583 -0.154514  0.173616  ...  0.165094 -0.045670 -0.238260   \n",
       "55569  0.243176  0.248512  0.035865  ...  0.128848 -0.477830 -0.289134   \n",
       "55570 -0.371960 -0.167659 -0.368950  ...  0.224181  0.044783  0.308011   \n",
       "55571  0.183375 -0.247024 -0.135890  ... -0.325720 -0.281259  0.140654   \n",
       "\n",
       "            SUV      TURN       VAR    return        date   permno  \\\n",
       "0      0.178494 -0.024265 -0.087374 -0.100016  20200131.0  10026.0   \n",
       "1     -0.290490 -0.090963  0.281565  0.607407  20200131.0  10028.0   \n",
       "2     -0.376418  0.057495 -0.253961 -0.075643  20200131.0  10032.0   \n",
       "3      0.244871 -0.209539 -0.393663 -0.098592  20200131.0  10044.0   \n",
       "4     -0.131909  0.046259 -0.186270 -0.115176  20200131.0  10051.0   \n",
       "...         ...       ...       ...       ...         ...      ...   \n",
       "55567 -0.409368  0.294199  0.186148  0.109665  20201231.0  93423.0   \n",
       "55568  0.201405 -0.213858 -0.084906  0.076239  20201231.0  93426.0   \n",
       "55569 -0.049415 -0.174724 -0.358491  0.135851  20201231.0  93427.0   \n",
       "55570  0.440047 -0.345304  0.119650  0.122605  20201231.0  93434.0   \n",
       "55571  0.337939  0.421501  0.077082  0.243252  20201231.0  93436.0   \n",
       "\n",
       "       monthly_update  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "55567             1.0  \n",
       "55568             1.0  \n",
       "55569             1.0  \n",
       "55570             1.0  \n",
       "55571             1.0  \n",
       "\n",
       "[55572 rows x 49 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2ME</th>\n",
       "      <th>AC</th>\n",
       "      <th>AT</th>\n",
       "      <th>ATO</th>\n",
       "      <th>B2M</th>\n",
       "      <th>BETA_d</th>\n",
       "      <th>BETA_m</th>\n",
       "      <th>C2A</th>\n",
       "      <th>CF2B</th>\n",
       "      <th>CF2P</th>\n",
       "      <th>...</th>\n",
       "      <th>S2P</th>\n",
       "      <th>SGA2S</th>\n",
       "      <th>SPREAD</th>\n",
       "      <th>SUV</th>\n",
       "      <th>TURN</th>\n",
       "      <th>VAR</th>\n",
       "      <th>return</th>\n",
       "      <th>date</th>\n",
       "      <th>permno</th>\n",
       "      <th>monthly_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55472</th>\n",
       "      <td>0.065386</td>\n",
       "      <td>-0.455878</td>\n",
       "      <td>-0.484783</td>\n",
       "      <td>-0.103923</td>\n",
       "      <td>0.361736</td>\n",
       "      <td>-0.369907</td>\n",
       "      <td>0.219719</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>-0.434524</td>\n",
       "      <td>-0.489327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440838</td>\n",
       "      <td>-0.229977</td>\n",
       "      <td>0.468462</td>\n",
       "      <td>0.462954</td>\n",
       "      <td>-0.067873</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>92688.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55473</th>\n",
       "      <td>0.468335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.290097</td>\n",
       "      <td>-0.156903</td>\n",
       "      <td>0.350616</td>\n",
       "      <td>0.174040</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>-0.120844</td>\n",
       "      <td>0.276786</td>\n",
       "      <td>0.182552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.052716</td>\n",
       "      <td>0.017799</td>\n",
       "      <td>-0.222376</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>92716.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55474</th>\n",
       "      <td>-0.199782</td>\n",
       "      <td>-0.275292</td>\n",
       "      <td>0.085507</td>\n",
       "      <td>0.255986</td>\n",
       "      <td>-0.244017</td>\n",
       "      <td>0.343714</td>\n",
       "      <td>0.161991</td>\n",
       "      <td>-0.362779</td>\n",
       "      <td>0.258185</td>\n",
       "      <td>0.019980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062810</td>\n",
       "      <td>-0.189329</td>\n",
       "      <td>-0.117634</td>\n",
       "      <td>-0.161358</td>\n",
       "      <td>-0.096225</td>\n",
       "      <td>0.040727</td>\n",
       "      <td>0.030843</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>92729.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55475</th>\n",
       "      <td>-0.148054</td>\n",
       "      <td>-0.291680</td>\n",
       "      <td>-0.351208</td>\n",
       "      <td>-0.157667</td>\n",
       "      <td>-0.155306</td>\n",
       "      <td>-0.042782</td>\n",
       "      <td>0.224305</td>\n",
       "      <td>-0.206452</td>\n",
       "      <td>-0.178323</td>\n",
       "      <td>-0.257260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305362</td>\n",
       "      <td>0.328259</td>\n",
       "      <td>0.411832</td>\n",
       "      <td>0.438876</td>\n",
       "      <td>0.131676</td>\n",
       "      <td>0.260009</td>\n",
       "      <td>0.494497</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>92747.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55476</th>\n",
       "      <td>0.493715</td>\n",
       "      <td>-0.462811</td>\n",
       "      <td>0.059420</td>\n",
       "      <td>-0.274070</td>\n",
       "      <td>0.494440</td>\n",
       "      <td>0.229336</td>\n",
       "      <td>0.321149</td>\n",
       "      <td>-0.356328</td>\n",
       "      <td>-0.117312</td>\n",
       "      <td>0.483619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481629</td>\n",
       "      <td>0.129619</td>\n",
       "      <td>0.142035</td>\n",
       "      <td>0.370023</td>\n",
       "      <td>0.257136</td>\n",
       "      <td>0.085826</td>\n",
       "      <td>-0.326797</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>92748.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55567</th>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.284116</td>\n",
       "      <td>0.167874</td>\n",
       "      <td>-0.186449</td>\n",
       "      <td>-0.446821</td>\n",
       "      <td>0.447905</td>\n",
       "      <td>0.403696</td>\n",
       "      <td>-0.228784</td>\n",
       "      <td>0.462054</td>\n",
       "      <td>0.326508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236594</td>\n",
       "      <td>0.126663</td>\n",
       "      <td>0.057781</td>\n",
       "      <td>-0.409368</td>\n",
       "      <td>0.294199</td>\n",
       "      <td>0.186148</td>\n",
       "      <td>0.109665</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>93423.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55568</th>\n",
       "      <td>0.026710</td>\n",
       "      <td>0.365112</td>\n",
       "      <td>-0.156763</td>\n",
       "      <td>0.131431</td>\n",
       "      <td>0.155547</td>\n",
       "      <td>-0.020664</td>\n",
       "      <td>0.106151</td>\n",
       "      <td>0.155583</td>\n",
       "      <td>-0.154514</td>\n",
       "      <td>0.173616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165094</td>\n",
       "      <td>-0.045670</td>\n",
       "      <td>-0.238260</td>\n",
       "      <td>0.201405</td>\n",
       "      <td>-0.213858</td>\n",
       "      <td>-0.084906</td>\n",
       "      <td>0.076239</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>93426.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55569</th>\n",
       "      <td>-0.185037</td>\n",
       "      <td>0.082414</td>\n",
       "      <td>0.051449</td>\n",
       "      <td>0.402191</td>\n",
       "      <td>-0.041939</td>\n",
       "      <td>-0.333527</td>\n",
       "      <td>-0.158484</td>\n",
       "      <td>0.243176</td>\n",
       "      <td>0.248512</td>\n",
       "      <td>0.035865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128848</td>\n",
       "      <td>-0.477830</td>\n",
       "      <td>-0.289134</td>\n",
       "      <td>-0.049415</td>\n",
       "      <td>-0.174724</td>\n",
       "      <td>-0.358491</td>\n",
       "      <td>0.135851</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>93427.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55570</th>\n",
       "      <td>0.148779</td>\n",
       "      <td>-0.433186</td>\n",
       "      <td>-0.287681</td>\n",
       "      <td>-0.025981</td>\n",
       "      <td>0.175127</td>\n",
       "      <td>-0.445576</td>\n",
       "      <td>-0.313056</td>\n",
       "      <td>-0.371960</td>\n",
       "      <td>-0.167659</td>\n",
       "      <td>-0.368950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224181</td>\n",
       "      <td>0.044783</td>\n",
       "      <td>0.308011</td>\n",
       "      <td>0.440047</td>\n",
       "      <td>-0.345304</td>\n",
       "      <td>0.119650</td>\n",
       "      <td>0.122605</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>93434.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55571</th>\n",
       "      <td>-0.481629</td>\n",
       "      <td>0.209108</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.151808</td>\n",
       "      <td>-0.422649</td>\n",
       "      <td>0.352445</td>\n",
       "      <td>0.355678</td>\n",
       "      <td>0.183375</td>\n",
       "      <td>-0.247024</td>\n",
       "      <td>-0.135890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.325720</td>\n",
       "      <td>-0.281259</td>\n",
       "      <td>0.140654</td>\n",
       "      <td>0.337939</td>\n",
       "      <td>0.421501</td>\n",
       "      <td>0.077082</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>20201231.0</td>\n",
       "      <td>93436.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           A2ME        AC        AT       ATO       B2M    BETA_d    BETA_m  \\\n",
       "55472  0.065386 -0.455878 -0.484783 -0.103923  0.361736 -0.369907  0.219719   \n",
       "55473  0.468335       NaN  0.290097 -0.156903  0.350616  0.174040 -0.068384   \n",
       "55474 -0.199782 -0.275292  0.085507  0.255986 -0.244017  0.343714  0.161991   \n",
       "55475 -0.148054 -0.291680 -0.351208 -0.157667 -0.155306 -0.042782  0.224305   \n",
       "55476  0.493715 -0.462811  0.059420 -0.274070  0.494440  0.229336  0.321149   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "55567  0.004230  0.284116  0.167874 -0.186449 -0.446821  0.447905  0.403696   \n",
       "55568  0.026710  0.365112 -0.156763  0.131431  0.155547 -0.020664  0.106151   \n",
       "55569 -0.185037  0.082414  0.051449  0.402191 -0.041939 -0.333527 -0.158484   \n",
       "55570  0.148779 -0.433186 -0.287681 -0.025981  0.175127 -0.445576 -0.313056   \n",
       "55571 -0.481629  0.209108  0.455556  0.151808 -0.422649  0.352445  0.355678   \n",
       "\n",
       "            C2A      CF2B      CF2P  ...       S2P     SGA2S    SPREAD  \\\n",
       "55472  0.009677 -0.434524 -0.489327  ...  0.141758       NaN  0.440838   \n",
       "55473 -0.120844  0.276786  0.182552  ...  0.032274       NaN -0.052716   \n",
       "55474 -0.362779  0.258185  0.019980  ...  0.062810 -0.189329 -0.117634   \n",
       "55475 -0.206452 -0.178323 -0.257260  ... -0.305362  0.328259  0.411832   \n",
       "55476 -0.356328 -0.117312  0.483619  ...  0.481629  0.129619  0.142035   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "55567 -0.228784  0.462054  0.326508  ... -0.236594  0.126663  0.057781   \n",
       "55568  0.155583 -0.154514  0.173616  ...  0.165094 -0.045670 -0.238260   \n",
       "55569  0.243176  0.248512  0.035865  ...  0.128848 -0.477830 -0.289134   \n",
       "55570 -0.371960 -0.167659 -0.368950  ...  0.224181  0.044783  0.308011   \n",
       "55571  0.183375 -0.247024 -0.135890  ... -0.325720 -0.281259  0.140654   \n",
       "\n",
       "            SUV      TURN       VAR    return        date   permno  \\\n",
       "55472 -0.229977  0.468462  0.462954 -0.067873  20201231.0  92688.0   \n",
       "55473  0.017799 -0.222376  0.017717  0.083333  20201231.0  92716.0   \n",
       "55474 -0.161358 -0.096225  0.040727  0.030843  20201231.0  92729.0   \n",
       "55475  0.438876  0.131676  0.260009  0.494497  20201231.0  92747.0   \n",
       "55476  0.370023  0.257136  0.085826 -0.326797  20201231.0  92748.0   \n",
       "...         ...       ...       ...       ...         ...      ...   \n",
       "55567 -0.409368  0.294199  0.186148  0.109665  20201231.0  93423.0   \n",
       "55568  0.201405 -0.213858 -0.084906  0.076239  20201231.0  93426.0   \n",
       "55569 -0.049415 -0.174724 -0.358491  0.135851  20201231.0  93427.0   \n",
       "55570  0.440047 -0.345304  0.119650  0.122605  20201231.0  93434.0   \n",
       "55571  0.337939  0.421501  0.077082  0.243252  20201231.0  93436.0   \n",
       "\n",
       "       monthly_update  \n",
       "55472             1.0  \n",
       "55473             1.0  \n",
       "55474             1.0  \n",
       "55475             1.0  \n",
       "55476             1.0  \n",
       "...               ...  \n",
       "55567             1.0  \n",
       "55568             1.0  \n",
       "55569             1.0  \n",
       "55570             1.0  \n",
       "55571             1.0  \n",
       "\n",
       "[100 rows x 49 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_perm = data['permno'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4954"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
