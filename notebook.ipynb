{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import important libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns \n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from numpy.linalg import LinAlgError \n",
    "from functools import reduce \n",
    "\n",
    "from sklearn.neighbors import KernelDensity, KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Simulated Experiment\n",
    "\n",
    "class Simulated_Experiment:\n",
    "    def __init__(self, T, N, L, nan_rate=0.4):\n",
    "        \"\"\" \n",
    "        T: Number of days\n",
    "        N: Number of stocks/companies\n",
    "        L: Number of characteristics\n",
    "        nan_rate: Rate that controls the masking rate for the simulated data\n",
    "        \n",
    "        \"\"\"\n",
    "        self.T = T \n",
    "        self.N = N \n",
    "        self.L = L  \n",
    "\n",
    "        self.nan_rate = nan_rate \n",
    "\n",
    "\n",
    "    def generate_masked_data(self):\n",
    "        T, N, L = self.T, self.N, self.L \n",
    "        panel = np.zeros((T,N,L))\n",
    "        for t in range(T):\n",
    "            np.random.seed(t) # for reproducibility \n",
    "            # Generate random mean vector (mu)\n",
    "            mu = np.random.normal(size=L)\n",
    "            # Generate random covariance matrix (Sigma)\n",
    "            Sigma = np.random.rand(L,L)\n",
    "            Sigma = Sigma @ Sigma.T # Ensure positive-definite matrix \n",
    "            panel[t,::] = np.random.multivariate_normal(mu, Sigma, N)\n",
    "\n",
    "        raw_chars = panel \n",
    "\n",
    "        self.raw_chars = raw_chars # raw characteristics\n",
    "\n",
    "        # convert the raw_chars into rank_chars \n",
    "        rank_chars = percentile_rank_panel(raw_chars)\n",
    "        self.rank_chars = rank_chars \n",
    "\n",
    "\n",
    "        # Simulate missing data \n",
    "        masked_rank_chars = np.array([simulate_nan(rank_chars[t], nan_rate=self.nan_rate)['X'] for t in range(T)])\n",
    "\n",
    "        self.masked_rank_chars = masked_rank_chars\n",
    "\n",
    "        return masked_rank_chars\n",
    "    \n",
    "    def evaluate_imputation_performance(self, method='xs', params=\"\"):\n",
    "        \"\"\" \n",
    "        Function can call any available imputation method \n",
    "        method could be 'em', 'xs', 'b_xs', 'xs-median', 'forward_filling'\n",
    "        \"\"\"\n",
    "\n",
    "        # create an object of Imputer and just use of the defaults\n",
    "        # then measure performance of imputation\n",
    "\n",
    "        impute_model = Imputer(self.masked_rank_chars)\n",
    "\n",
    "        # put params as input of each function\n",
    "        if method == 'em':\n",
    "            rank_imputed_chars = impute_model.impute_with_em(params)\n",
    "        \n",
    "        elif method == 'xs':\n",
    "            rank_imputed_chars = impute_model.impute_with_xs(params)\n",
    "\n",
    "        else: # Default \n",
    "            print(\"Method not recognied\")\n",
    "            print(\"Using default cross-sectional model\")\n",
    "\n",
    "            rank_imputed_chars = impute_model.impute_with_xs()\n",
    "        \n",
    "        self.rank_imputed_chars = impute_model.rank_imputed_chars \n",
    "        self.missing_mask_overall = impute_model.missing_mask_overall\n",
    "\n",
    "        # calculate metrics for the imputation model\n",
    "        # evaluate performance\n",
    "        metrics = self.evaluate_imputations(self.rank_chars)\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def evaluate_imputations(self, rank_chars):\n",
    "        \"\"\" \n",
    "        Adapted function to measure the quality of the imputation\n",
    "        rank_chars : the complete ranked characteristics\n",
    "        \"\"\"\n",
    "        truth_panel = rank_chars\n",
    "\n",
    "        tgt = np.copy(truth_panel)\n",
    "        T, N, L = tgt.shape\n",
    "        imputed = np.zeros((T,N,L)) # initialized the panel\n",
    "        imputed[~self.missing_mask_overall] = np.nan # everywhere should be nan\n",
    "        imputed[self.missing_mask_overall] = self.rank_imputed_chars[self.missing_mask_overall]\n",
    "\n",
    "        tgt[np.isnan(imputed)] = np.nan # anyone that is still empty in the imputed chars, make them empty in the target\n",
    "\n",
    "        # compute rmse and r2\n",
    "        rmse = compute_rmse(tgt, imputed)\n",
    "        r2 = compute_r2(tgt, imputed)\n",
    "\n",
    "        metrics = {'rmse': rmse,\n",
    "                   'r2': r2}\n",
    "        \n",
    "        print(metrics)\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "class Imputer:\n",
    "    def __init__(self, masked_rank_chars):\n",
    "        \"\"\" \n",
    "        masked_rank_chars : panel data with missing points\n",
    "        \"\"\"\n",
    "        self.masked_rank_chars = masked_rank_chars\n",
    "\n",
    "        T, N, L = masked_rank_chars.shape \n",
    "\n",
    "        self.T, self. N, self.L = T, N, L \n",
    "\n",
    "        # set defaults for the different methods\n",
    "\n",
    "        # em\n",
    "        self.em_params = {\n",
    "            'max_iter': 20,\n",
    "            'eps': 1e-03,\n",
    "            'min_xs_obs': 1\n",
    "        }\n",
    "\n",
    "        # xs-median\n",
    "        self.xs_median_params = {\n",
    "            'min_xs_obs': 1\n",
    "        }\n",
    "\n",
    "        # xs\n",
    "        self.xs_params = {\n",
    "            'K': L,\n",
    "            'time_varying_loadings': True,\n",
    "            'reg_param': 0.01/L,\n",
    "            'eval_weight_lmbda': True,\n",
    "            'shrink_lmbda': False,\n",
    "            'min_xs_obs': 1\n",
    "        }\n",
    "\n",
    "        # b-xs\n",
    "        self.b_xs_params = {\n",
    "            'K': L,\n",
    "            'time_varying_loadings': True,\n",
    "            'reg_param': 0.01/L,\n",
    "            'eval_weight_lmbda': True,\n",
    "            'shrink_lmbda': False,\n",
    "            'min_xs_obs': 1\n",
    "        }\n",
    "\n",
    "    def impute_with_em(self, params=\"\"):\n",
    "\n",
    "        # check if params is empty\n",
    "\n",
    "        if params == \"\":\n",
    "            params = self.em_params \n",
    "        \n",
    "        else:\n",
    "            params = params \n",
    "\n",
    "        max_iter = params['max_iter']\n",
    "        eps = params['eps']\n",
    "        min_xs_obs = params['min_xs_obs']\n",
    "\n",
    "        T,N,L = self.masked_rank_chars.shape \n",
    "        min_chars = min_xs_obs # minimum number of characteristics that must be observed\n",
    "        char_panel = np.copy(self.masked_rank_chars)\n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "        self.missing_mask_overall = missing_mask_overall \n",
    "        return_mask = np.sum(~missing_mask_overall, axis=2) >= min_chars \n",
    "\n",
    "        char_panel[np.sum(~np.isnan(missing_mask_overall), axis=2) < min_chars] = np.nan \n",
    "\n",
    "        em_imputations = np.zeros((T,N,L)) # T X N X L \n",
    "        em_imputations[:,:] = np.nan \n",
    "\n",
    "        imputations = [impute_em(char_panel[t]) for t in range(T)]\n",
    "\n",
    "        for t in range(T):\n",
    "            em_imputations[t, return_mask[t]] = imputations[t]['X_imputed'][return_mask[t]] # copying imputations into em_imputations\n",
    "\n",
    "        self.rank_imputed_chars = em_imputations \n",
    "\n",
    "        return self.rank_imputed_chars \n",
    "    \n",
    "    def impute_with_xs_median(self, params=\"\"):\n",
    "        # check if params is empty\n",
    "\n",
    "        if params == \"\":\n",
    "            params = self.xs_median_params \n",
    "\n",
    "        else:\n",
    "            params = params \n",
    "\n",
    "        min_chars = params['min_xs_obs']\n",
    "\n",
    "        # run the baseline code\n",
    "        char_panel = np.copy(self.masked_rank_chars)\n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "\n",
    "        char_panel[np.sum(~np.isnan(missing_mask_overall), axis=2) < min_chars] = np.nan \n",
    "\n",
    "        # get the missing mask after min_chars is enforced \n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "        self.missing_mask_overall = missing_mask_overall \n",
    "\n",
    "        return_mask = np.sum(~missing_mask_overall, axis=2) >= min_chars \n",
    "\n",
    "        imputed_chars = np.copy(char_panel) # this is the rank data \n",
    "\n",
    "        new_imputation = xs_median_impute(imputed_chars)\n",
    "\n",
    "        # revisit this --- perhaps using the return_mask is best\n",
    "        imputed_chars[missing_mask_overall] = new_imputation[missing_mask_overall]\n",
    "\n",
    "        self.rank_imputed_chars = imputed_chars\n",
    "\n",
    "        return self.rank_imputed_chars \n",
    "    \n",
    "    def impute_with_forward_filling(self, params=\"\"):\n",
    "        \"\"\" \n",
    "        Make Imputations using forward filling\n",
    "        \"\"\"\n",
    "\n",
    "        # run the baseline code\n",
    "        char_panel = np.copy(self.masked_rank_chars)\n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "\n",
    "        self.missing_mask_overall = missing_mask_overall\n",
    "\n",
    "        imputed_chars = np.copy(char_panel) # rank data\n",
    "        \n",
    "        new_imputation = simple_impute(imputed_chars)\n",
    "\n",
    "        # revisit this --- perhaps using the return_mask is best\n",
    "        imputed_chars[missing_mask_overall] = new_imputation[missing_mask_overall]\n",
    "\n",
    "        self.rank_imputed_chars = imputed_chars\n",
    "\n",
    "        return self.rank_imputed_chars \n",
    "\n",
    "\n",
    "    def impute_with_xs(self, params=\"\"):\n",
    "        \"\"\" \n",
    "        Make Imputations with cross-sectional approach\n",
    "        \"\"\"\n",
    "\n",
    "        if params == \"\": # check if params is empty\n",
    "            params = self.xs_params\n",
    "        else:\n",
    "            params = params \n",
    "\n",
    "        self.min_xs_obs = params['min_xs_obs']\n",
    "        self.K = params['K']\n",
    "        self.time_varying_loadings = params['time_varying_loadings']\n",
    "        self.reg_param = params['reg_param']\n",
    "        self.eval_weight_lmbda = params['eval_weight_lmbda']\n",
    "        self.shrink_lmbda = params['shrink_lmbda']\n",
    "\n",
    "\n",
    "        # run the baseline code\n",
    "        char_panel = np.copy(self.masked_rank_chars)\n",
    "        min_chars = self.min_xs_obs\n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "\n",
    "        char_panel[np.sum(~np.isnan(missing_mask_overall), axis=2) < min_chars] = np.nan \n",
    "\n",
    "        # obtain modified missing mask after enforcing min_chars\n",
    "        \n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "        self.missing_mask_overall = missing_mask_overall \n",
    "        return_mask = np.sum(~missing_mask_overall, axis=2) >= min_chars\n",
    "\n",
    "        imputed_chars = np.copy(char_panel) # rank data\n",
    "        \n",
    "        mu = np.nanmean(imputed_chars, axis=1) # important for the algorithm stability\n",
    "\n",
    "        lmbda, cov_mat = estimate_lmbda(imputed_chars, self.T, self.K,self.min_xs_obs, \n",
    "                                        self.time_varying_loadings,\n",
    "                                        reg=self.reg_param, eval_weight_lmbda = self.eval_weight_lmbda,\n",
    "                                        shrink_lmbda=self.shrink_lmbda)\n",
    "\n",
    "        assert np.sum(np.isnan(lmbda)) == 0, f\"lambda should contain no nans, {np.argwhere(np.isnan(lmbda))}\"\n",
    "\n",
    "        gamma_ts = np.zeros((char_panel.shape[0], char_panel.shape[1], self.K))  # T X N X K \n",
    "        gamma_ts[:,:] = np.nan \n",
    "\n",
    "        def get_gamma_t(ct, present, to_impute, lmbda, time_varying_lambdas, t):\n",
    "\n",
    "            if time_varying_lambdas:\n",
    "                gamma_t = lmbda[t].T.dot(ct.T).T # gamma_t = ct @ lmbda[t]\n",
    "                gamma_t = get_optimal_A(lmbda[t].T, gamma_t, present, ct, L=self.L, \n",
    "                                        idxs=to_impute, reg=self.reg_param, mu=mu[t])\n",
    "            else:\n",
    "                gamma_t = lmbda[t].T.dot(ct.T).T # gamma_t = ct @ lmbda[t]\n",
    "                gamma_t = get_optimal_A(lmbda.T, gamma_t, present, ct, L=self.L, \n",
    "                                        idxs=to_impute, reg=self.reg_param, mu=mu[t])\n",
    "            \n",
    "            return gamma_t \n",
    "        \n",
    "        gammas = [get_gamma_t(\n",
    "            ct=char_panel[t],\n",
    "            present= ~np.isnan(char_panel[t]),\n",
    "            to_impute= np.argwhere(return_mask[t]).squeeze(),\n",
    "            lmbda=lmbda,\n",
    "            time_varying_lambdas=self.time_varying_loadings, t=t,\n",
    "        ) for t in range(self.T)]\n",
    "\n",
    "        for t in range(self.T):\n",
    "            gamma_ts[t, return_mask[t]] = gammas[t][return_mask[t]] # copying gamma into gamma_ts \n",
    "\n",
    "        self.rank_imputed_chars = imputed_chars\n",
    "\n",
    "        return self.rank_imputed_chars \n",
    "    \n",
    "\n",
    "    def impute_with_b_xs(self, params=\"\"):\n",
    "        \"\"\" \n",
    "        Cross-sectional imputation + backward time series information\n",
    "        \"\"\"\n",
    "\n",
    "        if params == \"\": # check if params is empty\n",
    "            params = self.b_xs_params\n",
    "        else:\n",
    "            params = params \n",
    "\n",
    "        self.min_xs_obs = params['min_xs_obs']\n",
    "        self.K = params['K']\n",
    "        self.time_varying_loadings = params['time_varying_loadings']\n",
    "        self.reg_param = params['reg_param']\n",
    "        self.eval_weight_lmbda = params['eval_weight_lmbda']\n",
    "        self.shrink_lmbda = params['shrink_lmbda']\n",
    "\n",
    "        # run the xs function\n",
    "        xs_imputation = self.impute_with_xs(params)\n",
    "\n",
    "        # run the baseline code\n",
    "        char_panel = np.copy(self.masked_rank_chars)\n",
    "        min_chars = self.min_xs_obs\n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "\n",
    "        char_panel[np.sum(~np.isnan(missing_mask_overall), axis=2) < min_chars] = np.nan \n",
    "\n",
    "        # obtain modified missing mask after enforcing min_chars\n",
    "        \n",
    "        missing_mask_overall = np.isnan(char_panel)\n",
    "        self.missing_mask_overall = missing_mask_overall \n",
    "        return_mask = np.sum(~missing_mask_overall, axis=2) >= min_chars\n",
    "\n",
    "        imputed_chars = np.copy(char_panel) # rank data\n",
    "        \n",
    "        mu = np.nanmean(imputed_chars, axis=1) # important for the algorithm stability\n",
    "\n",
    "        # compute the residuals\n",
    "        residuals = simple_impute(imputed_chars) - xs_imputation\n",
    "\n",
    "        local_bw = impute_chars(char_panel, xs_imputation, residuals, suff_stat_method='last_val', constant_beta=False)\n",
    "\n",
    "        imputed_chars[missing_mask_overall] = local_bw[missing_mask_overall]\n",
    "\n",
    "        local_bw_missing_mask = np.isnan(imputed_chars) # obtain the missing mask in the already filled data\n",
    "\n",
    "        # improving data quality by imputing from the xs_imputation\n",
    "        imputed_chars[local_bw_missing_mask] = xs_imputation[local_bw_missing_mask]\n",
    "\n",
    "        self.rank_imputed_chars = imputed_chars\n",
    "\n",
    "        return self.rank_imputed_chars \n",
    "    \n",
    "    def evaluate_imputations(self, rank_chars):\n",
    "        \"\"\" \n",
    "        Adapted function to measure the quality of the imputation\n",
    "        rank_chars : the complete ranked characteristics\n",
    "        \"\"\"\n",
    "        truth_panel = rank_chars\n",
    "\n",
    "        tgt = np.copy(truth_panel)\n",
    "        T, N, L = tgt.shape\n",
    "        imputed = np.zeros((T,N,L)) # initialized the panel\n",
    "        imputed[~self.missing_mask_overall] = np.nan # everywhere should be nan\n",
    "        imputed[self.missing_mask_overall] = self.rank_imputed_chars[self.missing_mask_overall]\n",
    "\n",
    "        tgt[np.isnan(imputed)] = np.nan # anyone that is still empty in the imputed chars, make them empty in the target\n",
    "\n",
    "        # compute rmse and r2\n",
    "        rmse = compute_rmse(tgt, imputed)\n",
    "        r2 = compute_r2(tgt, imputed)\n",
    "\n",
    "        metrics = {'rmse': rmse,\n",
    "                   'r2': r2}\n",
    "        \n",
    "        print(metrics)\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "\n",
    "# helper functions\n",
    "def percentile_rank(x, UNK=np.nan):\n",
    "    \"\"\" \n",
    "    utility method to quantile rank a vector\n",
    "    \"\"\"\n",
    "\n",
    "    mask = np.logical_not(np.isnan(x))\n",
    "    x_copy = np.copy(x)\n",
    "    x_mask = x_copy[mask]\n",
    "    n = len(x_mask)\n",
    "\n",
    "    if n > 1:\n",
    "        temp = [(i, x_mask[i]) for i in range(n)]\n",
    "        temp_sorted = sorted(temp, key=lambda t: t[1])\n",
    "        idx = sorted([(temp_sorted[i][0], i) for i in range(n)], key=lambda t: t[0])\n",
    "        x_copy[mask] = np.array([idx[i][1] for i in range(n)]) / (n-1)\n",
    "\n",
    "    elif n == 1:\n",
    "        x_copy[mask] = 0.5\n",
    "    return x_copy \n",
    "\n",
    "def percentile_rank_panel(char_panel): # very useful function\n",
    "    \"\"\" \n",
    "    utility method to quantile rank the characteristics or features\n",
    "    \"\"\"\n",
    "    ret_panel = np.zeros(char_panel.shape)\n",
    "    ret_panel[:,:,:] = np.nan\n",
    "    for t in range(char_panel.shape[0]):\n",
    "        for i in range(char_panel.shape[2]):\n",
    "            ret_panel[t,:,i] = percentile_rank(char_panel[t,:,i])\n",
    "\n",
    "\n",
    "    return ret_panel\n",
    "\n",
    "\n",
    "def get_cov_mat(char_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the covariance matrix of a partially observed panel using the method from Xiong & Pelger\n",
    "    Parameters\n",
    "    ----------\n",
    "        char_matrix : the panel over which to calculate the covariance N x L\n",
    "    \"\"\"\n",
    "    ct_int = (~np.isnan(char_matrix)).astype(float)\n",
    "    ct = np.nan_to_num(char_matrix)\n",
    "    mu = np.nanmean(char_matrix, axis=0).reshape(-1, 1)\n",
    "    temp = ct.T.dot(ct) \n",
    "    temp_counts = ct_int.T.dot(ct_int)\n",
    "    sigma_t = temp / temp_counts - mu @ mu.T\n",
    "    return mu,sigma_t\n",
    "\n",
    "\n",
    "def get_data_panel(data, N_column_name, start_date=None):\n",
    "    \"\"\" \n",
    "    N_column_name could be the company column\n",
    "    fetch data from user input\n",
    "    \"\"\"\n",
    "\n",
    "    if start_date is not None:\n",
    "        data = data.loc[data.date >= start_date]\n",
    "    else:\n",
    "        pass \n",
    "\n",
    "    dates = data['date'].unique() \n",
    "    dates.sort() # sort the dates\n",
    "    Ns = data[N_column_name].unique() # obtain the unique Ns\n",
    "\n",
    "    date_vals = [date for date in dates]\n",
    "    chars = np.array([char for char in data.columns.tolist() if char not in ['date', N_column_name]])\n",
    "    chars.sort()\n",
    "\n",
    "    rank_chars = np.zeros((len(date_vals), Ns.shape[0], len(chars))) # create the panel\n",
    "    rank_chars[:,:,:] = np.nan \n",
    "\n",
    "\n",
    "    N_map = {}\n",
    "    for i, N_ in enumerate(Ns):\n",
    "        N_map[N_] = i \n",
    "\n",
    "    for i, date in enumerate(dates):\n",
    "        date_data = data.loc[data['date'] == date].sort_values(by=N_column_name)\n",
    "        date_Ns = date_data[N_column_name].tolist()\n",
    "        N_inds_for_date = [N_map[N_] for N_ in date_Ns]\n",
    "        rank_chars[i, N_inds_for_date,:] = date_data[chars].to_numpy()\n",
    "\n",
    "    return rank_chars, chars, date_vals, Ns\n",
    "\n",
    "\n",
    "def estimate_lambda(char_panel, num_days_train, K, min_chars,\n",
    "                    time_varying_loadings=False, eval_weight_lmbda=True,\n",
    "                    shrink_lmbda=False, reg=0, window_size=1):\n",
    "    \n",
    "    \"\"\" \n",
    "    Fit the cross-sectional Loadings using XP method\n",
    "    Parameters\n",
    "    ----------\n",
    "        char_panel: the panel over which to fit the model T X N X L\n",
    "        num_days_train: if fitting a global model, the number of days over which to fit the loadings\n",
    "        K: the number of cross-sectional factors\n",
    "        min_chars: the minimum number of observations required for an entity to be included in the sample\n",
    "        time_varying_loadings = False: whether or not to allow the loadings to vary over time\n",
    "\n",
    "    Formula\n",
    "    --------\n",
    "    \\hat{\\Lambda^t} = \\hat{V^t} (\\hat{D^t}^{1/2})\n",
    "\n",
    "    \"\"\"\n",
    "    # create a mask to show when the minimum number of characteristics is observed\n",
    "    min_char_mask = np.expand_dims(np.sum(~np.isnan(char_panel), axis=2) >= min_chars, axis=2)\n",
    "\n",
    "    cov_mats = []\n",
    "\n",
    "    for t in range(num_days_train):\n",
    "        cov_mats.append(get_cov_mat(char_panel[t][1])) # Send the N X L to get the characteristic covariance matrix of dim L X L\n",
    "\n",
    "    cov_mats_sum = sum(cov_mats) * (1/len(cov_mats)) # Takes the average of the covariance matrix\n",
    "\n",
    "    if time_varying_loadings: # local-based models have time-varying lambdas\n",
    "        lmbda = []\n",
    "        cov_mat = []\n",
    "        printed = False \n",
    "\n",
    "        for t in range(len(cov_mats)): # in this case, we want to avoid look-ahead bias, so we keep cov_mat as it was at day t\n",
    "            cov_mats_sum = sum(cov_mats[max(0, t-window_size+1): t+1]) * (1/window_size)\n",
    "\n",
    "            eig_vals, eig_vects = np.linalg.eigh(cov_mats_sum) # obtain the eigenvalues and eigenvectors, from the covariance matrix\n",
    "            idx = np.abs(eig_vals).argsort()[::-1]\n",
    "            if eval_weight_lmbda:\n",
    "                if shrink_lmbda:\n",
    "                    lmbda.append(eig_vects[:, idx[:K]] *\n",
    "                                np.maximum(np.sqrt(np.sqrt(np.maximum(eig_vals[idx[:K]].reshape(1,-1),0))) - reg, 0))\n",
    "                else:\n",
    "                    lmbda.append(eig_vects[:, idx[:K]] * np.sqrt(np.maximum(eig_vals[idx[:K]].reshape(1,-1), 0)))\n",
    "            else:\n",
    "                lmbda.append(eig_vects[:, idx[:K]])\n",
    "            assert np.all(~np.isnan(lmbda[-1])), lmbda\n",
    "            cov_mat.append(cov_mats_sum)\n",
    "\n",
    "\n",
    "    else:\n",
    "        tgt_mat = cov_mats_sum\n",
    "        eigh_vals, eig_vects = np.linalg.eigh(tgt_mat)\n",
    "\n",
    "        idx = np.abs(eig_vals).argsort()[::-1]\n",
    "        if eval_weight_lmbda:\n",
    "            if shrink_lmbda:\n",
    "                lmbda = eig_vects[:, idx[:K]] * np.maximum(np.sqrt(np.sqrt(eig_vals[idx[:K]].reshape(1,-1))) - reg, 0)\n",
    "            else:\n",
    "                lmbda = eig_vects[:, idx[:K]] * np.sqrt(np.maximum(0, eig_vals[idx[:K]].reshape(1, -1)))\n",
    "        else:\n",
    "            lmbda = eig_vects[:, idx[:K]]\n",
    "        cov_mat = tgt_mat\n",
    "    return lmbda, cov_mat \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_optimal_A(B, A, present, cl, L, idxs=[], reg=0, mu=None):\n",
    "    \"\"\"\n",
    "    Get optimal A for cl = AB given that X is (potentially) missing data\n",
    "    Parameters\n",
    "    ----------\n",
    "        B : matrix B\n",
    "        A : matrix A, will be overwritten\n",
    "        present: boolean mask of present data\n",
    "        cl: matrix cl\n",
    "        idxs: indexes which to impute\n",
    "        reg: optinal regularization penalty\n",
    "        mu: mean of the partially-observed characteristics\n",
    "    \"\"\"\n",
    "    A[:,:] = np.nan\n",
    "    for i in idxs:\n",
    "        present_i = present[i,:]\n",
    "        Xi = cl[i,:]\n",
    "        Xi = Xi[present_i]\n",
    "        Bi = B[:,present_i]\n",
    "        assert np.all(~np.isnan(Bi)) and np.all(~np.isinf(Bi))\n",
    "        effective_reg = reg \n",
    "        lmbda = effective_reg * np.eye(Bi.shape[1])\n",
    "\n",
    "        if mu is not None:\n",
    "            Xi = Xi - mu.T[present_i]\n",
    "        try:\n",
    "            A[i,:] = Bi @ np.linalg.lstsq(Bi.T @ Bi / L + lmbda, Xi / L, rcond=0)[0]\n",
    "        except LinAlgError as e:\n",
    "            lmbda = np.eye(Bi.shape[1])\n",
    "            A[i,:] = Bi @ np.linalg.lstsq(Bi.T @ Bi / L + lmbda, Xi / L, rcond=0)[0]\n",
    "    return A\n",
    "\n",
    "\n",
    "\n",
    "def get_sufficient_statistics_last_val(characteristics_panel, max_delta=None,\n",
    "                                      residuals=None):\n",
    "    \"\"\"\n",
    "    Get the last observed value for a panel time series \n",
    "    Parameters\n",
    "    ----------\n",
    "        characteristics_panel : the time series panel, T x N x L\n",
    "        max_delta=None : Optional, the maximum lag which is allowed for a previously observed value\n",
    "        residuals=None : Optional, residuals T x N x L, the residuals the factor model applied to the time\n",
    "                        series panel\n",
    "    \"\"\"\n",
    "    T, N, L = characteristics_panel.shape\n",
    "    last_val = np.copy(characteristics_panel[0])\n",
    "    if residuals is not None:\n",
    "        last_resid = np.copy(residuals[0])\n",
    "\n",
    "    lag_amount = np.zeros_like(last_val)\n",
    "    lag_amount[:] = np.nan\n",
    "    if residuals is None:\n",
    "        sufficient_statistics = np.zeros((T,N,L, 1), dtype=float)\n",
    "    else:\n",
    "        sufficient_statistics = np.zeros((T,N,L, 2), dtype=float)\n",
    "    sufficient_statistics[:,:,:,:] = np.nan\n",
    "    deltas = np.copy(sufficient_statistics[:,:,:,0])\n",
    "    for t in range(1, T):\n",
    "        lag_amount += 1\n",
    "        sufficient_statistics[t, :, :, 0] = np.copy(last_val)\n",
    "        deltas[t] = np.copy(lag_amount)\n",
    "        present_t = ~np.isnan(characteristics_panel[t])\n",
    "        last_val[present_t] = np.copy(characteristics_panel[t, present_t])\n",
    "        if residuals is not None:\n",
    "            sufficient_statistics[t, :, :, 1] = np.copy(last_resid)\n",
    "            last_resid[present_t] = np.copy(residuals[t, present_t])\n",
    "        lag_amount[present_t] = 0\n",
    "        if max_delta is not None:\n",
    "            last_val[lag_amount >= max_delta] = np.nan\n",
    "    return sufficient_statistics, deltas\n",
    "\n",
    "\n",
    "def impute_chars(char_data, imputed_chars, residuals=None, \n",
    "                 suff_stat_method='None', constant_beta=False):\n",
    "    \"\"\"\n",
    "    run the imputation for a given configuration\n",
    "    Parameters\n",
    "    ----------\n",
    "        char_data : the time series panel, T x N x L\n",
    "        imputed_chars: the cross-sectional imputation of the time series panel\n",
    "        residuals=None : Optional, residuals T x N x L, the residuals the factor model applied to the time\n",
    "                        series panel\n",
    "        suff_stat_method=None : Optional, the type of information to add to the cross sectional panel in the \n",
    "                        imputation\n",
    "        constant_beta=False: whether or not to allow time variation in the loadings of the model\n",
    "    \"\"\"\n",
    "    if suff_stat_method == 'last_val':\n",
    "        suff_stats, _ = get_sufficient_statistics_last_val(char_data, max_delta=None,\n",
    "                                                                           residuals=residuals)\n",
    "        if len(suff_stats.shape) == 3:\n",
    "            suff_stats = np.expand_dims(suff_stats, axis=3)\n",
    "                \n",
    "    elif suff_stat_method == 'None':\n",
    "        suff_stats = None\n",
    "            \n",
    "    if suff_stats is None:\n",
    "        return imputed_chars\n",
    "    else:\n",
    "        return impute_beta_combined_regression(\n",
    "            char_data, imputed_chars, sufficient_statistics=suff_stats, \n",
    "            constant_beta=constant_beta\n",
    "        )\n",
    "\n",
    "def impute_beta_combined_regression(characteristics_panel, xs_imps, sufficient_statistics=None, \n",
    "                                    constant_beta=False, get_betas=False, gamma_ts=None, use_factors=False, reg=None):\n",
    "    \"\"\"\n",
    "    run the imputation regression for a given configuration\n",
    "    Parameters\n",
    "    ----------\n",
    "        char_data : the time series panel, T x N x L\n",
    "        xs_imps: the cross-sectional imputation of the time series panel\n",
    "        sufficient_statistics=None : Optional, the information to add to the cross sectaial panel in the imputation\n",
    "        constant_beta=False: whether or not to allow time variation in the loadings of the model\n",
    "        get_betas=False: whether or not to return the learned betas\n",
    "        \n",
    "    \"\"\"\n",
    "    T, N, L = characteristics_panel.shape\n",
    "    K = 0\n",
    "    if xs_imps is not None:\n",
    "        K += 1\n",
    "    if sufficient_statistics is not None:\n",
    "        K += sufficient_statistics.shape[3]\n",
    "\n",
    "    betas = np.zeros((T, L, K))\n",
    "    imputed_data = np.copy(characteristics_panel)\n",
    "    imputed_data[:,:,:]=np.nan\n",
    "    \n",
    "    for l in range(L):\n",
    "        fit_suff_stats = []\n",
    "        fit_tgts = []\n",
    "        inds = []\n",
    "        curr_ind = 0\n",
    "        all_suff_stats = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            inds.append(curr_ind)\n",
    "            \n",
    "            if xs_imps is not None:\n",
    "                suff_stat = np.concatenate([xs_imps[t,:,l:l+1], sufficient_statistics[t,:,l]], axis=1)\n",
    "            else:\n",
    "                suff_stat = sufficient_statistics[t,:,l]\n",
    "            \n",
    "            available_for_imputation = np.all(~np.isnan(suff_stat), axis=1)\n",
    "            available_for_fit = np.logical_and(~np.isnan(characteristics_panel[t,:,l]),\n",
    "                                                  available_for_imputation)\n",
    "            all_suff_stats.append(suff_stat)\n",
    "\n",
    "            fit_suff_stats.append(suff_stat[available_for_fit, :])\n",
    "            fit_tgts.append(characteristics_panel[t,available_for_fit,l])\n",
    "            curr_ind += np.sum(available_for_fit)\n",
    "        \n",
    "        \n",
    "        inds.append(curr_ind)\n",
    "        fit_suff_stats = np.concatenate(fit_suff_stats, axis=0)\n",
    "        fit_tgts = np.concatenate(fit_tgts, axis=0)\n",
    "        \n",
    "        if constant_beta:\n",
    "\n",
    "            beta = np.linalg.lstsq(fit_suff_stats, fit_tgts, rcond=None)[0]\n",
    "                \n",
    "            betas[:,l,:] = beta.reshape(1, -1)\n",
    "        else:\n",
    "            for t in range(T):\n",
    "                beta_l_t = np.linalg.lstsq(fit_suff_stats[inds[t]:inds[t+1]],\n",
    "                                       fit_tgts[inds[t]:inds[t+1]], rcond=None)[0]\n",
    "                betas[t,l,:] = beta_l_t\n",
    "                if np.any(np.isnan(beta_l_t)):\n",
    "                    print(\"should be no nans, t=\", t,)\n",
    "                \n",
    "        for t in range(T):\n",
    "            beta_l_t = betas[t,l]\n",
    "            suff_stat = all_suff_stats[t]\n",
    "            available_for_imputation = np.all(~np.isnan(suff_stat), axis=1)\n",
    "            imputed_data[t,available_for_imputation,l] = suff_stat[available_for_imputation,:] @ beta_l_t\n",
    "            \n",
    "    if get_betas:\n",
    "        return imputed_data, betas\n",
    "    else:\n",
    "        return imputed_data\n",
    "\n",
    "\n",
    "\n",
    "def get_oos_estimates_given_loadings(chars, reg, Lmbda, time_varying_lmbda=False, get_factors=False):\n",
    "    \"\"\"\n",
    "    Generate the finite-sample correction to the cross-sectionally imputed data\n",
    "    Parameters\n",
    "    ----------\n",
    "        chars : the time series panel, T x N x L\n",
    "        Lmbda : the loadings in the Xiong - Pelger model\n",
    "        time_varying_lmbda=False: whether or the loadings are time varying\n",
    "        get_factors=False: whether or not to return the factors, or the imputed values        \n",
    "    \"\"\"\n",
    "    C = chars.shape[-1]\n",
    "    def impute_t(t_chars, reg, C, Lmbda, get_factors=False):\n",
    "        if not get_factors:\n",
    "            imputation = np.copy(t_chars) * np.nan\n",
    "        else:\n",
    "            imputation = np.zeros((t_chars.shape[0], t_chars.shape[1], Lmbda.shape[1])) * np.nan\n",
    "        mask = ~np.isnan(t_chars)\n",
    "        net_mask = np.sum(mask, axis=1)\n",
    "        K = Lmbda.shape[1]\n",
    "        for n in range(t_chars.shape[0]):\n",
    "            if net_mask[n] == 1:\n",
    "                imputation[n,:] = 0\n",
    "            elif net_mask[n] > 1:\n",
    "                for i in range(C):\n",
    "                    tmp = mask[n, i]\n",
    "                    mask[n,i] = False\n",
    "                    y = t_chars[n, mask[n]]\n",
    "                    X = Lmbda[mask[n], :]\n",
    "                    L = np.eye(K) * reg\n",
    "                    params = np.linalg.lstsq(X.T @ X + L, X.T @ y, rcond=None)[0]\n",
    "                    if get_factors:\n",
    "                        imputation[n,i] = params\n",
    "                    else:\n",
    "                        imputation[n,i] = Lmbda[i] @ params\n",
    "                    \n",
    "                    mask[n,i] = tmp\n",
    "        return np.expand_dims(imputation, axis=0)\n",
    "    chars = [chars_t for chars_t in chars]\n",
    "    \n",
    "    if time_varying_lmbda:\n",
    "        imputation = list(Parallel(n_jobs=60)(delayed(impute_t)(chars_t, reg, C, l, get_factors=get_factors) \n",
    "                                              for chars_t, l in zip(chars, Lmbda)))\n",
    "    else:\n",
    "        imputation = list(Parallel(n_jobs=60)(delayed(impute_t)(chars_t, reg, C, Lmbda, get_factors=get_factors)\n",
    "                                              for chars_t in chars))\n",
    "    return np.concatenate(imputation, axis=0)\n",
    "\n",
    "\n",
    "def simple_impute(char_panel):\n",
    "    \"\"\" \n",
    "    Imputes using the last value of the characteristic time series - the forward filling\n",
    "    \n",
    "    \"\"\"\n",
    "    imputed_panel = np.copy(char_panel)\n",
    "    imputed_panel[:,:,:] = np.nan\n",
    "    imputed_panel[0] = np.copy(char_panel[0])\n",
    "\n",
    "    for t in range(1, imputed_panel.shape[0]):\n",
    "        present_t_l = ~np.isnan(char_panel[t-1])\n",
    "        imputed_t_1 = ~np.isnan(imputed_panel[t-1])\n",
    "        imputed_panel[t, present_t_l] = char_panel[t-1, present_t_l]\n",
    "        imputed_panel[t, np.logical_and(~present_t_l,\n",
    "                                        imputed_t_1)] = imputed_panel[t-1,\n",
    "                                                                      np.logical_and(~present_t_l, imputed_t_1)]\n",
    "        imputed_panel[t, ~np.logical_or(imputed_t_1, present_t_l)] = np.nan \n",
    "\n",
    "    return imputed_panel\n",
    "\n",
    "\n",
    "def xs_median_impute(char_panel):\n",
    "    \"\"\" \n",
    "    Imputes using the cross-sectional median for each time period and characteristic\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    imputed_panel = np.copy(char_panel)\n",
    "    for t in range(imputed_panel.shape[0]):\n",
    "        for c in range(imputed_panel.shape[2]):\n",
    "            present_t_1 = ~np.isnan(char_panel[t,:,c])\n",
    "            imputed_panel[t,:,c] = np.median(char_panel[t, present_t_1, c])\n",
    "    return imputed_panel\n",
    "\n",
    "def impute_em(X, max_iter=50, eps=1e-08):\n",
    "    \"\"\" \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    nr, nc = X.shape\n",
    "    C = np.isnan(X) == False \n",
    "\n",
    "    # Collect M_i and O_i's \n",
    "    one_to_nc = np.arange(1, nc+1, step=1)\n",
    "    M = one_to_nc * (C==False) - 1\n",
    "    O = one_to_nc * C - 1\n",
    "\n",
    "    # Generate Mu_0 and Sigma_0\n",
    "    Mu = np.nanmean(X, axis=0)\n",
    "    observed_rows = np.where(np.isnan(sum(X.T)) == False)[0]\n",
    "    S = np.cov(X[observed_rows, ].T)\n",
    "    if np.isnan(S).any():\n",
    "        S = np.diag(np.nanvar(X, axis = 0))\n",
    "\n",
    "    # Start updating\n",
    "    Mu_tilde, S_tilde = {}, {}\n",
    "    X_tilde = X.copy()\n",
    "    no_conv = True \n",
    "    iteration = 0 \n",
    "    while no_conv and iteration < max_iter:\n",
    "        for i in range(nr):\n",
    "            S_tilde[i] = np.zeros(nc ** 2).reshape(nc, nc)\n",
    "            if set(O[i, ]) != set(one_to_nc - 1): # missing component exists\n",
    "                M_i, O_i = M[i, ][M[i, ] != -1], O[i,][O[i, ] != -1]\n",
    "                S_MM = S[np.ix_(M_i, M_i)]\n",
    "                S_MO = S[np.ix_(M_i, O_i)]\n",
    "                S_OM = S_MO.T \n",
    "                S_OO = S[np.ix_(O_i, O_i)]\n",
    "                Mu_tilde[i] = Mu[np.ix_(M_i)] +\\\n",
    "                    S_MO @ np.linalg.inv(S_OO) @\\\n",
    "                    (X_tilde[i, O_i]) - Mu[np.ix_(O_i)]\n",
    "                X_tilde[i, M_i] = Mu_tilde[i]\n",
    "                S_MM_O = S_MM - S_MO @ np.linalg.inv(S_OO) @ S_OM\n",
    "                S_tilde[i][np.ix_(M_i, M_i)] = S_MM_O\n",
    "        Mu_new = np.mean(X_tilde, axis=0)\n",
    "        S_new = np.cov(X_tilde.T, bias=1) +\\\n",
    "            reduce(np.add, S_tilde.values()) / nr \n",
    "        no_conv = \\\n",
    "            np.linalg.norm(Mu - Mu_new) >= eps or\\\n",
    "            np.linalg.norm(S - S_new, ord=2) >= eps \n",
    "        \n",
    "        Mu = Mu_new\n",
    "        S = S_new \n",
    "        iteration += 1 \n",
    "\n",
    "    result = {\n",
    "        'mu': Mu,\n",
    "        'Sigma': S,\n",
    "        'X_imputed': X_tilde,\n",
    "        'C': C,\n",
    "        'iteration': iteration\n",
    "    }\n",
    "\n",
    "    return result \n",
    "\n",
    "\n",
    "                    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
